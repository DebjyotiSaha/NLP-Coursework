{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "excited-attraction",
   "metadata": {},
   "source": [
    "# Intent Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-context",
   "metadata": {},
   "source": [
    "<p> NLP Individual Submission </p>\n",
    "<p> Name- Debjyoti Saha</p>\n",
    "<p> Student ID- 6706459</p>\n",
    "<p> Group- 1</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-perspective",
   "metadata": {},
   "source": [
    "<p> Intent Classification is mainly used to understand the context of the text words given by the user. In this indivudual submission I have explored some different techniques through which we can classify the intent of the chatbot. This is the 1st Python file (.ipynb) and the second python file contains a initial stage chatbot which works on Intent Classification.</p>\n",
    "\n",
    "<p> The dataset used in this Python file is a substitution dataset for Intent Classification. In total, I have used 2 datasets to satisfy the conditions using Python NLTK libraries.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-replacement",
   "metadata": {},
   "source": [
    "<p> The datasets are taken from Kaggle and some of the libraries and specification a referred from GitHub, Kaggle and Python documentation. The links to the dataset are given below.</p>\n",
    "\n",
    "<p> Dataset Links:-</p> \n",
    "    1. \"Text Commands.csv\" - https://github.com/KoushikiDasgupta/Intent-Analysis-for-Offline-Voice-Commanding/blob/main/CNN%20model1/TextCommands.csv </p>\n",
    "    2. Atis Intent Train and Test - https://www.kaggle.com/datasets/hassanamin/atis-airlinetravelinformationsystem </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "moderate-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-toyota",
   "metadata": {},
   "source": [
    "## Intent Classification using Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tender-former",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(r'D:\\Surrey\\Semester\\Semester 2\\NLP\\TextCommands.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accredited-county",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>misc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Undo the last sentence</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Undo the last word</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you undo the last sentence</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Please undo the text</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Undo the selected text</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text  label misc\n",
       "0          Undo the last sentence      1  NaN\n",
       "1              Undo the last word      1  NaN\n",
       "2  Can you undo the last sentence      1  NaN\n",
       "3            Please undo the text      1  NaN\n",
       "4          Undo the selected text      1  NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns=['text', 'label', 'misc']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-ethiopia",
   "metadata": {},
   "source": [
    "<p> The dataset contains different labels. The total intents labelled are from 1 to 26. The dataset needs to be in balanced manner. </p>\n",
    "\n",
    "<p> For data preprocessing, we need to go through Tokenizing, Sequence Padding. Tokenization is the collection of unique words from the dataset and are assigned to integer. Padding, on the other hand represents the dataset with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "historic-indianapolis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data tensorflow (399, 10)\n",
      "Label tensorflow (399, 27)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "#tf.keras.utils.to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "MAX_SEQUENCE_LENGTH=10\n",
    "MAX_NUM_WORDS=5000\n",
    "tokenizer=Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(data['text'])\n",
    "sequences=tokenizer.texts_to_sequences(data['text'])\n",
    "word_index=tokenizer.word_index\n",
    "#print('Unique tokens are:' %len(word_index))\n",
    "data1=pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "labels=to_categorical(np.asarray(data['label']))\n",
    "print('Data tensorflow', data1.shape)\n",
    "print('Label tensorflow', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "imperial-single",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT=0.1\n",
    "indices=np.arange(data1.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data1=data1[indices]\n",
    "labels=labels[indices]\n",
    "num_validation_samples=int(VALIDATION_SPLIT * data1.shape[0])\n",
    "x_train=data1[:-num_validation_samples]\n",
    "y_train=labels[:-num_validation_samples]\n",
    "x_val=data1[-num_validation_samples:]\n",
    "y_val=labels[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "electrical-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Flatten\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.initializers import Constant\n",
    "EMBEDDING_DIM=60\n",
    "num_words=min(MAX_NUM_WORDS, len(word_index) +1)\n",
    "embedding_layer=Embedding(num_words, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH, trainable=True)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "prerequisite-assets",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-litigation",
   "metadata": {},
   "source": [
    "<p> Reference Link: - https://www.researchgate.net/figure/Block-diagram-of-CNN-architecture_fig2_341019121"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-recipe",
   "metadata": {},
   "source": [
    "<p> Why I have used CNN as one of my technique?</p>\n",
    "\n",
    "<p> As we have seen in lectures, neural networks can identify relevant bigrams, trigrams, n-grams depending on the kernel size. The order of words doesn't matter here and this is one of the advantage of using CNN in detecting the Intent. </p>\n",
    "<p> Similar to sentiment analysis, the CNN rectifies the text by the presence or absence of some phrases.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "greater-glory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 10, 60)            8580      \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 8, 64)             11584     \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 6, 64)             12352     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 3, 64)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 192)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               19300     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 27)                2727      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,543\n",
      "Trainable params: 54,543\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequence_input=Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences=embedding_layer(sequence_input)\n",
    "x=Conv1D(64, 3, activation='relu')(embedded_sequences)\n",
    "x=Conv1D(64, 3, activation='relu')(x)\n",
    "x=MaxPooling1D(2)(x)\n",
    "x=Flatten()(x)\n",
    "x=Dense(100, activation='relu')(x)\n",
    "preds=Dense(27, activation='softmax')(x)\n",
    "model=Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "funded-serve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "8/8 [==============================] - 1s 26ms/step - loss: 3.2819 - acc: 0.0861 - val_loss: 3.2537 - val_acc: 0.1026\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.2143 - acc: 0.1361 - val_loss: 3.1915 - val_acc: 0.1538\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.1113 - acc: 0.1639 - val_loss: 3.0775 - val_acc: 0.1795\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.9785 - acc: 0.2194 - val_loss: 2.8949 - val_acc: 0.2308\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.8030 - acc: 0.2667 - val_loss: 2.7676 - val_acc: 0.2564\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.6240 - acc: 0.2833 - val_loss: 2.5221 - val_acc: 0.2821\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.4240 - acc: 0.3028 - val_loss: 2.4229 - val_acc: 0.3333\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.2324 - acc: 0.3778 - val_loss: 2.2712 - val_acc: 0.4359\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 2.3921 - acc: 0.380 - 0s 5ms/step - loss: 2.0337 - acc: 0.4583 - val_loss: 2.0637 - val_acc: 0.3590\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.8446 - acc: 0.5222 - val_loss: 1.9210 - val_acc: 0.3846\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.6845 - acc: 0.5472 - val_loss: 1.8482 - val_acc: 0.4615\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.5264 - acc: 0.6167 - val_loss: 1.8284 - val_acc: 0.4615\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3862 - acc: 0.6556 - val_loss: 1.6268 - val_acc: 0.4615\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.2439 - acc: 0.6889 - val_loss: 1.5626 - val_acc: 0.5385\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.1063 - acc: 0.7111 - val_loss: 1.4383 - val_acc: 0.6923\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.9984 - acc: 0.7750 - val_loss: 1.3176 - val_acc: 0.5897\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.8776 - acc: 0.8056 - val_loss: 1.3434 - val_acc: 0.6154\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7787 - acc: 0.8083 - val_loss: 1.3681 - val_acc: 0.6154\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6911 - acc: 0.8472 - val_loss: 1.1493 - val_acc: 0.6154\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5977 - acc: 0.8833 - val_loss: 1.1556 - val_acc: 0.5897\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5073 - acc: 0.8861 - val_loss: 1.1300 - val_acc: 0.6410\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4387 - acc: 0.9056 - val_loss: 1.0695 - val_acc: 0.7179\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3763 - acc: 0.9361 - val_loss: 0.9544 - val_acc: 0.7692\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3212 - acc: 0.9583 - val_loss: 0.7516 - val_acc: 0.7436\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2728 - acc: 0.9500 - val_loss: 0.9284 - val_acc: 0.7179\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2345 - acc: 0.9694 - val_loss: 0.7980 - val_acc: 0.7949\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1824 - acc: 0.9806 - val_loss: 1.0629 - val_acc: 0.6667\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1604 - acc: 0.9778 - val_loss: 0.5685 - val_acc: 0.8974\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1184 - acc: 0.9944 - val_loss: 0.6399 - val_acc: 0.8718\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0977 - acc: 0.9972 - val_loss: 0.8208 - val_acc: 0.7436\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0798 - acc: 0.9917 - val_loss: 0.6140 - val_acc: 0.8462\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0670 - acc: 0.9972 - val_loss: 1.0401 - val_acc: 0.7692\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0827 - acc: 0.9806 - val_loss: 0.8031 - val_acc: 0.7436\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0524 - acc: 0.9917 - val_loss: 0.4875 - val_acc: 0.8974\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0303 - acc: 1.0000 - val_loss: 0.5941 - val_acc: 0.8974\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0366 - acc: 0.9944 - val_loss: 0.5401 - val_acc: 0.8974\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0188 - acc: 1.0000 - val_loss: 0.4537 - val_acc: 0.9231\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.4323 - val_acc: 0.9487\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0374 - acc: 0.9944 - val_loss: 0.4662 - val_acc: 0.8974\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0137 - acc: 0.9972 - val_loss: 0.4594 - val_acc: 0.9231\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.4583 - val_acc: 0.9487\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.9113 - val_acc: 0.8205\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.5304 - val_acc: 0.8974\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.4889 - val_acc: 0.9231\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.4798 - val_acc: 0.9487\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.5332 - val_acc: 0.9487\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.4506 - val_acc: 0.9487\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.4455 - val_acc: 0.9487\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0198 - acc: 0.9944 - val_loss: 0.4423 - val_acc: 0.9487\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.4538 - val_acc: 0.9487\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.8975e-04 - acc: 1.0000 - val_loss: 0.4675 - val_acc: 0.9487\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.8598e-04 - acc: 1.0000 - val_loss: 0.5331 - val_acc: 0.9231\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7.5850e-04 - acc: 1.0000 - val_loss: 0.5493 - val_acc: 0.9487\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7.9410e-04 - acc: 1.0000 - val_loss: 0.4594 - val_acc: 0.9231\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0294 - acc: 0.9972 - val_loss: 0.4694 - val_acc: 0.9487\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.3228e-04 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.9231\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4.1348e-04 - acc: 1.0000 - val_loss: 0.4936 - val_acc: 0.9487\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.1869e-04 - acc: 1.0000 - val_loss: 0.4957 - val_acc: 0.9487\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.9753e-04 - acc: 1.0000 - val_loss: 0.4815 - val_acc: 0.9487\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.0248e-04 - acc: 1.0000 - val_loss: 0.4857 - val_acc: 0.9487\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7229e-04 - acc: 1.0000 - val_loss: 0.4774 - val_acc: 0.9487\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.5666e-04 - acc: 1.0000 - val_loss: 0.5742 - val_acc: 0.9231\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.5441e-04 - acc: 1.0000 - val_loss: 0.8747 - val_acc: 0.8462\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0608 - acc: 0.9889 - val_loss: 0.4926 - val_acc: 0.9487\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.9424e-04 - acc: 1.0000 - val_loss: 0.4877 - val_acc: 0.9487\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.5275e-04 - acc: 1.0000 - val_loss: 0.4697 - val_acc: 0.9231\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.2586e-04 - acc: 1.0000 - val_loss: 0.4633 - val_acc: 0.9487\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.1484e-04 - acc: 1.0000 - val_loss: 0.4850 - val_acc: 0.9487\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8.5628e-05 - acc: 1.0000 - val_loss: 0.4972 - val_acc: 0.9487\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.8734e-05 - acc: 1.0000 - val_loss: 0.5067 - val_acc: 0.9231\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7.2280e-05 - acc: 1.0000 - val_loss: 0.4551 - val_acc: 0.9487\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.9442e-05 - acc: 1.0000 - val_loss: 0.5054 - val_acc: 0.9487\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.2009e-05 - acc: 1.0000 - val_loss: 0.5084 - val_acc: 0.9487\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3213e-05 - acc: 1.0000 - val_loss: 0.5337 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.7566e-05 - acc: 1.0000 - val_loss: 0.4807 - val_acc: 0.9487\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.3364e-05 - acc: 1.0000 - val_loss: 0.4459 - val_acc: 0.9487\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.5219e-05 - acc: 1.0000 - val_loss: 0.4968 - val_acc: 0.9487\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.4800e-05 - acc: 1.0000 - val_loss: 0.4189 - val_acc: 0.9487\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.6487e-05 - acc: 1.0000 - val_loss: 0.5144 - val_acc: 0.9487\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0750e-05 - acc: 1.0000 - val_loss: 0.5263 - val_acc: 0.9487\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 6.8837e-06 - acc: 1.0000 - val_loss: 0.6722 - val_acc: 0.9487\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0180 - acc: 0.9972 - val_loss: 0.5355 - val_acc: 0.9487\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.6225e-05 - acc: 1.0000 - val_loss: 0.5036 - val_acc: 0.9487\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.7857e-05 - acc: 1.0000 - val_loss: 0.4865 - val_acc: 0.9487\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.3002e-05 - acc: 1.0000 - val_loss: 0.4877 - val_acc: 0.9487\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9.4286e-06 - acc: 1.0000 - val_loss: 0.4901 - val_acc: 0.9487\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.2697e-06 - acc: 1.0000 - val_loss: 0.5165 - val_acc: 0.9487\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.1608e-06 - acc: 1.0000 - val_loss: 0.4967 - val_acc: 0.9487\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.8276e-06 - acc: 1.0000 - val_loss: 0.4919 - val_acc: 0.9487\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.0837e-06 - acc: 1.0000 - val_loss: 0.4765 - val_acc: 0.9487\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 3.3629e-06 - acc: 1.0000 - val_loss: 0.4373 - val_acc: 0.9487\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.8792e-06 - acc: 1.0000 - val_loss: 0.4169 - val_acc: 0.9487\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5.3694e-06 - acc: 1.0000 - val_loss: 0.4918 - val_acc: 0.9487\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.9828e-06 - acc: 1.0000 - val_loss: 0.5512 - val_acc: 0.9487\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.9312e-06 - acc: 1.0000 - val_loss: 0.4448 - val_acc: 0.9487\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.3653e-06 - acc: 1.0000 - val_loss: 0.4843 - val_acc: 0.9487\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.1388e-06 - acc: 1.0000 - val_loss: 0.4572 - val_acc: 0.9487\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.4037e-06 - acc: 1.0000 - val_loss: 0.5031 - val_acc: 0.9487\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.0697e-07 - acc: 1.0000 - val_loss: 0.5092 - val_acc: 0.9487\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.1477e-06 - acc: 1.0000 - val_loss: 0.4888 - val_acc: 0.9487\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.4439e-07 - acc: 1.0000 - val_loss: 0.4706 - val_acc: 0.9487\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.3611e-07 - acc: 1.0000 - val_loss: 0.5124 - val_acc: 0.9487\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.5995e-07 - acc: 1.0000 - val_loss: 0.5242 - val_acc: 0.9487\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.3875e-07 - acc: 1.0000 - val_loss: 0.5446 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.9405e-07 - acc: 1.0000 - val_loss: 0.5243 - val_acc: 0.9487\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.1027e-07 - acc: 1.0000 - val_loss: 0.5924 - val_acc: 0.9487\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.5465e-07 - acc: 1.0000 - val_loss: 0.5805 - val_acc: 0.9487\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.4702e-07 - acc: 1.0000 - val_loss: 0.5606 - val_acc: 0.9487\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8.8082e-08 - acc: 1.0000 - val_loss: 0.5512 - val_acc: 0.9487\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 8.2784e-08 - acc: 1.0000 - val_loss: 0.5618 - val_acc: 0.9487\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0199e-07 - acc: 1.0000 - val_loss: 0.5972 - val_acc: 0.9487\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.0995e-08 - acc: 1.0000 - val_loss: 0.5410 - val_acc: 0.9487\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.9008e-08 - acc: 1.0000 - val_loss: 0.5997 - val_acc: 0.9487\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.8412e-08 - acc: 1.0000 - val_loss: 0.5651 - val_acc: 0.9487\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.1723e-08 - acc: 1.0000 - val_loss: 0.5774 - val_acc: 0.9487\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.8147e-08 - acc: 1.0000 - val_loss: 0.5716 - val_acc: 0.9487\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.1127e-08 - acc: 1.0000 - val_loss: 0.5823 - val_acc: 0.9487\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.8809e-08 - acc: 1.0000 - val_loss: 0.5768 - val_acc: 0.9487\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.7087e-08 - acc: 1.0000 - val_loss: 0.5801 - val_acc: 0.9487\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.0199e-08 - acc: 1.0000 - val_loss: 0.6076 - val_acc: 0.9487\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1855e-08 - acc: 1.0000 - val_loss: 0.5899 - val_acc: 0.9487\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.6226e-08 - acc: 1.0000 - val_loss: 0.5944 - val_acc: 0.9487\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.5895e-08 - acc: 1.0000 - val_loss: 0.5799 - val_acc: 0.9487\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.7881e-08 - acc: 1.0000 - val_loss: 0.6080 - val_acc: 0.9487\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4107e-08 - acc: 1.0000 - val_loss: 0.5901 - val_acc: 0.9487\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.1921e-08 - acc: 1.0000 - val_loss: 0.6221 - val_acc: 0.9487\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.5232e-08 - acc: 1.0000 - val_loss: 0.6065 - val_acc: 0.9487\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.2583e-08 - acc: 1.0000 - val_loss: 0.6091 - val_acc: 0.9487\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.9074e-08 - acc: 1.0000 - val_loss: 0.6076 - val_acc: 0.9487\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.1921e-08 - acc: 1.0000 - val_loss: 0.6049 - val_acc: 0.9487\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.1259e-08 - acc: 1.0000 - val_loss: 0.6127 - val_acc: 0.9487\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.2583e-08 - acc: 1.0000 - val_loss: 0.6114 - val_acc: 0.9487\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.3577e-08 - acc: 1.0000 - val_loss: 0.6244 - val_acc: 0.9487\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.3577e-08 - acc: 1.0000 - val_loss: 0.6228 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.2252e-08 - acc: 1.0000 - val_loss: 0.6509 - val_acc: 0.9487\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.5232e-08 - acc: 1.0000 - val_loss: 0.6223 - val_acc: 0.9487\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3245e-08 - acc: 1.0000 - val_loss: 0.6194 - val_acc: 0.9487\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.5563e-08 - acc: 1.0000 - val_loss: 0.6681 - val_acc: 0.9487\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0844 - acc: 0.9889 - val_loss: 0.6976 - val_acc: 0.9487\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.1479e-05 - acc: 1.0000 - val_loss: 0.7336 - val_acc: 0.9487\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4.6270e-06 - acc: 1.0000 - val_loss: 0.7190 - val_acc: 0.9487\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.8165e-06 - acc: 1.0000 - val_loss: 0.7493 - val_acc: 0.9487\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.1042e-06 - acc: 1.0000 - val_loss: 0.7561 - val_acc: 0.9487\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.5868e-06 - acc: 1.0000 - val_loss: 0.7398 - val_acc: 0.9487\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.1274e-06 - acc: 1.0000 - val_loss: 0.7571 - val_acc: 0.9487\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.6971e-06 - acc: 1.0000 - val_loss: 0.7479 - val_acc: 0.9487\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.2773e-06 - acc: 1.0000 - val_loss: 0.7755 - val_acc: 0.9487\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 9.7873e-07 - acc: 1.0000 - val_loss: 0.7550 - val_acc: 0.9487\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.1983e-07 - acc: 1.0000 - val_loss: 0.7639 - val_acc: 0.9487\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.0231e-07 - acc: 1.0000 - val_loss: 0.7582 - val_acc: 0.9487\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.5198e-07 - acc: 1.0000 - val_loss: 0.7491 - val_acc: 0.9487\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.5861e-07 - acc: 1.0000 - val_loss: 0.7516 - val_acc: 0.9487\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.8742e-07 - acc: 1.0000 - val_loss: 0.7519 - val_acc: 0.9487\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.2186e-07 - acc: 1.0000 - val_loss: 0.7456 - val_acc: 0.9487\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.7751e-08 - acc: 1.0000 - val_loss: 0.7342 - val_acc: 0.9487\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.8942e-08 - acc: 1.0000 - val_loss: 0.7322 - val_acc: 0.9487\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.7021e-08 - acc: 1.0000 - val_loss: 0.7298 - val_acc: 0.9487\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.1458e-08 - acc: 1.0000 - val_loss: 0.7210 - val_acc: 0.9487\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.2186e-08 - acc: 1.0000 - val_loss: 0.7102 - val_acc: 0.9487\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.6557e-08 - acc: 1.0000 - val_loss: 0.6986 - val_acc: 0.9487\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.3577e-08 - acc: 1.0000 - val_loss: 0.6779 - val_acc: 0.9487\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.1590e-08 - acc: 1.0000 - val_loss: 0.6721 - val_acc: 0.9487\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.9341e-09 - acc: 1.0000 - val_loss: 0.6654 - val_acc: 0.9487\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.9473e-09 - acc: 1.0000 - val_loss: 0.6430 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 9.6030e-09 - acc: 1.0000 - val_loss: 0.6486 - val_acc: 0.9487\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.6227e-09 - acc: 1.0000 - val_loss: 0.6535 - val_acc: 0.9487\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.9539e-09 - acc: 1.0000 - val_loss: 0.6457 - val_acc: 0.9487\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5.2982e-09 - acc: 1.0000 - val_loss: 0.6388 - val_acc: 0.9487\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.6227e-09 - acc: 1.0000 - val_loss: 0.6463 - val_acc: 0.9487\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.2916e-09 - acc: 1.0000 - val_loss: 0.6620 - val_acc: 0.9487\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.2718e-09 - acc: 1.0000 - val_loss: 0.6464 - val_acc: 0.9487\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.9539e-09 - acc: 1.0000 - val_loss: 0.6361 - val_acc: 0.9487\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8.6096e-09 - acc: 1.0000 - val_loss: 0.6026 - val_acc: 0.9487\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7.9473e-09 - acc: 1.0000 - val_loss: 0.6203 - val_acc: 0.9487\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7.9473e-09 - acc: 1.0000 - val_loss: 0.6416 - val_acc: 0.9487\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0928e-08 - acc: 1.0000 - val_loss: 0.6435 - val_acc: 0.9487\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7.2850e-09 - acc: 1.0000 - val_loss: 0.6470 - val_acc: 0.9487\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 9.9341e-09 - acc: 1.0000 - val_loss: 0.6474 - val_acc: 0.9487\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.5232e-08 - acc: 1.0000 - val_loss: 0.6917 - val_acc: 0.9487\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.7550e-08 - acc: 1.0000 - val_loss: 0.6182 - val_acc: 0.9487\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0928e-08 - acc: 1.0000 - val_loss: 0.6950 - val_acc: 0.9487\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.3245e-08 - acc: 1.0000 - val_loss: 0.6588 - val_acc: 0.9487\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0369 - acc: 0.9917 - val_loss: 0.8120 - val_acc: 0.8974\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.5786e-05 - acc: 1.0000 - val_loss: 0.7819 - val_acc: 0.8974\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.4107e-05 - acc: 1.0000 - val_loss: 0.7703 - val_acc: 0.8974\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.4043e-05 - acc: 1.0000 - val_loss: 0.7484 - val_acc: 0.8974\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.6651e-06 - acc: 1.0000 - val_loss: 0.7353 - val_acc: 0.8974\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.7191e-06 - acc: 1.0000 - val_loss: 0.7165 - val_acc: 0.8974\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4.0438e-06 - acc: 1.0000 - val_loss: 0.6717 - val_acc: 0.8974\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.7675e-06 - acc: 1.0000 - val_loss: 0.6662 - val_acc: 0.8974\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.7247e-06 - acc: 1.0000 - val_loss: 0.6567 - val_acc: 0.8974\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.2072e-06 - acc: 1.0000 - val_loss: 0.6472 - val_acc: 0.9487\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 8.5728e-07 - acc: 1.0000 - val_loss: 0.6380 - val_acc: 0.9231\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 6.1358e-07 - acc: 1.0000 - val_loss: 0.6186 - val_acc: 0.9231\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.2451e-07 - acc: 1.0000 - val_loss: 0.6241 - val_acc: 0.9231\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.0497e-07 - acc: 1.0000 - val_loss: 0.6141 - val_acc: 0.9231\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.1358e-07 - acc: 1.0000 - val_loss: 0.6094 - val_acc: 0.9231\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.5828e-07 - acc: 1.0000 - val_loss: 0.6125 - val_acc: 0.9231\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.1557e-07 - acc: 1.0000 - val_loss: 0.6151 - val_acc: 0.9231\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.5102e-08 - acc: 1.0000 - val_loss: 0.6008 - val_acc: 0.9231\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.3247e-08 - acc: 1.0000 - val_loss: 0.6192 - val_acc: 0.9231\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.4372e-08 - acc: 1.0000 - val_loss: 0.5930 - val_acc: 0.9487\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.1458e-08 - acc: 1.0000 - val_loss: 0.5941 - val_acc: 0.9231\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.3511e-08 - acc: 1.0000 - val_loss: 0.5945 - val_acc: 0.9744\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.0199e-08 - acc: 1.0000 - val_loss: 0.5987 - val_acc: 0.9487\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.6557e-08 - acc: 1.0000 - val_loss: 0.5979 - val_acc: 0.9487\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.2252e-08 - acc: 1.0000 - val_loss: 0.6106 - val_acc: 0.9487\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.6030e-09 - acc: 1.0000 - val_loss: 0.6008 - val_acc: 0.9487\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8.9407e-09 - acc: 1.0000 - val_loss: 0.6099 - val_acc: 0.9487\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5.6293e-09 - acc: 1.0000 - val_loss: 0.5755 - val_acc: 0.9744\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.9605e-09 - acc: 1.0000 - val_loss: 0.5870 - val_acc: 0.9744\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-09 - acc: 1.0000 - val_loss: 0.5839 - val_acc: 0.9744\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.6491e-09 - acc: 1.0000 - val_loss: 0.5874 - val_acc: 0.9744\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-09 - acc: 1.0000 - val_loss: 0.5890 - val_acc: 0.9487\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.9868e-09 - acc: 1.0000 - val_loss: 0.5918 - val_acc: 0.9487\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.6359e-09 - acc: 1.0000 - val_loss: 0.5958 - val_acc: 0.9487\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-09 - acc: 1.0000 - val_loss: 0.6126 - val_acc: 0.9487\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.2916e-09 - acc: 1.0000 - val_loss: 0.6253 - val_acc: 0.9487\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.9671e-09 - acc: 1.0000 - val_loss: 0.6050 - val_acc: 0.9487\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.6161e-09 - acc: 1.0000 - val_loss: 0.6654 - val_acc: 0.9487\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.9407e-09 - acc: 1.0000 - val_loss: 0.6113 - val_acc: 0.9487\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.7219e-08 - acc: 1.0000 - val_loss: 0.7088 - val_acc: 0.9487\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0338 - acc: 0.9944 - val_loss: 0.6629 - val_acc: 0.9487\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5.4515e-06 - acc: 1.0000 - val_loss: 0.6527 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4.2484e-06 - acc: 1.0000 - val_loss: 0.6446 - val_acc: 0.9487\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.0995e-06 - acc: 1.0000 - val_loss: 0.6262 - val_acc: 0.9487\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 6.1983e-07 - acc: 1.0000 - val_loss: 0.6197 - val_acc: 0.9487\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5.8407e-07 - acc: 1.0000 - val_loss: 0.6134 - val_acc: 0.9487\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5.3640e-07 - acc: 1.0000 - val_loss: 0.6089 - val_acc: 0.9487\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.6985e-07 - acc: 1.0000 - val_loss: 0.6161 - val_acc: 0.9231\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.0231e-07 - acc: 1.0000 - val_loss: 0.6010 - val_acc: 0.9487\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3675e-07 - acc: 1.0000 - val_loss: 0.5951 - val_acc: 0.9487\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.7450e-07 - acc: 1.0000 - val_loss: 0.5948 - val_acc: 0.9487\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.1258e-07 - acc: 1.0000 - val_loss: 0.5844 - val_acc: 0.9487\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.4934e-07 - acc: 1.0000 - val_loss: 0.5761 - val_acc: 0.9487\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.0596e-07 - acc: 1.0000 - val_loss: 0.5719 - val_acc: 0.9487\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.4836e-08 - acc: 1.0000 - val_loss: 0.5640 - val_acc: 0.9487\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5.1326e-08 - acc: 1.0000 - val_loss: 0.5740 - val_acc: 0.9231\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.0596e-08 - acc: 1.0000 - val_loss: 0.5691 - val_acc: 0.9231\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.6161e-09 - acc: 1.0000 - val_loss: 0.5637 - val_acc: 0.9231\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 7.6161e-09 - acc: 1.0000 - val_loss: 0.5480 - val_acc: 0.9487\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.6227e-09 - acc: 1.0000 - val_loss: 0.5531 - val_acc: 0.9487\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.2916e-09 - acc: 1.0000 - val_loss: 0.5532 - val_acc: 0.9487\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.6293e-09 - acc: 1.0000 - val_loss: 0.5464 - val_acc: 0.9231\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4.9671e-09 - acc: 1.0000 - val_loss: 0.5324 - val_acc: 0.9487\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4.9671e-09 - acc: 1.0000 - val_loss: 0.5387 - val_acc: 0.9487\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.3048e-09 - acc: 1.0000 - val_loss: 0.5339 - val_acc: 0.9487\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.9802e-09 - acc: 1.0000 - val_loss: 0.5316 - val_acc: 0.9487\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.3180e-09 - acc: 1.0000 - val_loss: 0.5296 - val_acc: 0.9487\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.3180e-09 - acc: 1.0000 - val_loss: 0.5335 - val_acc: 0.9487\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.9868e-09 - acc: 1.0000 - val_loss: 0.5399 - val_acc: 0.9487\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.6425e-09 - acc: 1.0000 - val_loss: 0.5549 - val_acc: 0.9487\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.6425e-09 - acc: 1.0000 - val_loss: 0.5474 - val_acc: 0.9487\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.0265e-08 - acc: 1.0000 - val_loss: 0.5550 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-09 - acc: 1.0000 - val_loss: 0.5920 - val_acc: 0.9487\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.9868e-09 - acc: 1.0000 - val_loss: 0.5708 - val_acc: 0.9487\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3114e-09 - acc: 1.0000 - val_loss: 0.5892 - val_acc: 0.9487\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.6359e-09 - acc: 1.0000 - val_loss: 0.5831 - val_acc: 0.9487\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.9605e-09 - acc: 1.0000 - val_loss: 0.5919 - val_acc: 0.9487\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.0596e-08 - acc: 1.0000 - val_loss: 0.6284 - val_acc: 0.9487\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.5895e-08 - acc: 1.0000 - val_loss: 0.5842 - val_acc: 0.9487\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2082 - acc: 0.9639 - val_loss: 0.8891 - val_acc: 0.8974\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3318e-05 - acc: 1.0000 - val_loss: 0.9094 - val_acc: 0.8974\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.8869e-06 - acc: 1.0000 - val_loss: 0.9359 - val_acc: 0.8974\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.2637e-06 - acc: 1.0000 - val_loss: 0.9603 - val_acc: 0.8974\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7.0497e-06 - acc: 1.0000 - val_loss: 0.9764 - val_acc: 0.8974\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5.9179e-06 - acc: 1.0000 - val_loss: 0.9802 - val_acc: 0.8974\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.0863e-06 - acc: 1.0000 - val_loss: 0.9815 - val_acc: 0.8974\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.1822e-06 - acc: 1.0000 - val_loss: 0.9837 - val_acc: 0.8974\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.4790e-06 - acc: 1.0000 - val_loss: 1.0023 - val_acc: 0.8974\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.3781e-06 - acc: 1.0000 - val_loss: 1.0227 - val_acc: 0.8974\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.6189e-06 - acc: 1.0000 - val_loss: 1.0095 - val_acc: 0.8974\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.3308e-06 - acc: 1.0000 - val_loss: 0.9975 - val_acc: 0.8974\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.0341e-06 - acc: 1.0000 - val_loss: 0.9716 - val_acc: 0.8974\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.9041e-07 - acc: 1.0000 - val_loss: 0.9901 - val_acc: 0.8974\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5.7187e-07 - acc: 1.0000 - val_loss: 0.9811 - val_acc: 0.8974\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.0266e-07 - acc: 1.0000 - val_loss: 0.9626 - val_acc: 0.8974\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.8809e-07 - acc: 1.0000 - val_loss: 0.9496 - val_acc: 0.8974\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.0564e-07 - acc: 1.0000 - val_loss: 0.9416 - val_acc: 0.9231\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.4636e-07 - acc: 1.0000 - val_loss: 0.9236 - val_acc: 0.9231\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.0928e-07 - acc: 1.0000 - val_loss: 0.9050 - val_acc: 0.9231\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.5168e-08 - acc: 1.0000 - val_loss: 0.8895 - val_acc: 0.9231\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.5300e-08 - acc: 1.0000 - val_loss: 0.8934 - val_acc: 0.9231\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.9405e-08 - acc: 1.0000 - val_loss: 0.8749 - val_acc: 0.9231\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.5829e-08 - acc: 1.0000 - val_loss: 0.8682 - val_acc: 0.9231\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.8875e-08 - acc: 1.0000 - val_loss: 0.8412 - val_acc: 0.9231\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.2914e-08 - acc: 1.0000 - val_loss: 0.8322 - val_acc: 0.9231\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8.6096e-09 - acc: 1.0000 - val_loss: 0.8346 - val_acc: 0.9231\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.9539e-09 - acc: 1.0000 - val_loss: 0.8231 - val_acc: 0.9487\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.6293e-09 - acc: 1.0000 - val_loss: 0.8154 - val_acc: 0.9487\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4.3048e-09 - acc: 1.0000 - val_loss: 0.8042 - val_acc: 0.9487\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.3180e-09 - acc: 1.0000 - val_loss: 0.8257 - val_acc: 0.9231\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.9868e-09 - acc: 1.0000 - val_loss: 0.8075 - val_acc: 0.9487\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 0.8033 - val_acc: 0.9487\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.9868e-09 - acc: 1.0000 - val_loss: 0.8067 - val_acc: 0.9487\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.3245e-09 - acc: 1.0000 - val_loss: 0.7971 - val_acc: 0.9487\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 0.7915 - val_acc: 0.9487\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.6425e-09 - acc: 1.0000 - val_loss: 0.7792 - val_acc: 0.9487\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.6557e-09 - acc: 1.0000 - val_loss: 0.8269 - val_acc: 0.9487\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.0199e-08 - acc: 1.0000 - val_loss: 0.8123 - val_acc: 0.9487\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.3180e-09 - acc: 1.0000 - val_loss: 0.8204 - val_acc: 0.9487\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.6557e-09 - acc: 1.0000 - val_loss: 0.8216 - val_acc: 0.9487\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.4901e-08 - acc: 1.0000 - val_loss: 0.7987 - val_acc: 0.9487\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.3245e-09 - acc: 1.0000 - val_loss: 0.7899 - val_acc: 0.9487\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.9868e-09 - acc: 1.0000 - val_loss: 0.8088 - val_acc: 0.9487\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4.9671e-09 - acc: 1.0000 - val_loss: 0.7585 - val_acc: 0.9487\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.5232e-08 - acc: 1.0000 - val_loss: 0.7910 - val_acc: 0.9487\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.3114e-09 - acc: 1.0000 - val_loss: 0.7888 - val_acc: 0.9487\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.8382e-06 - acc: 1.0000 - val_loss: 2.7895 - val_acc: 0.6410\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1863 - acc: 0.9528 - val_loss: 0.9203 - val_acc: 0.8974\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4914e-05 - acc: 1.0000 - val_loss: 0.9156 - val_acc: 0.8974\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.1553e-05 - acc: 1.0000 - val_loss: 0.9139 - val_acc: 0.8974\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.4393e-05 - acc: 1.0000 - val_loss: 0.9146 - val_acc: 0.8974\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9.9578e-06 - acc: 1.0000 - val_loss: 0.9164 - val_acc: 0.8974\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7.2387e-06 - acc: 1.0000 - val_loss: 0.9129 - val_acc: 0.8974\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.1276e-06 - acc: 1.0000 - val_loss: 0.9200 - val_acc: 0.8974\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.8360e-06 - acc: 1.0000 - val_loss: 0.9246 - val_acc: 0.8974\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.6999e-06 - acc: 1.0000 - val_loss: 0.8985 - val_acc: 0.8974\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.0927e-06 - acc: 1.0000 - val_loss: 0.9291 - val_acc: 0.8974\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.6123e-06 - acc: 1.0000 - val_loss: 0.8809 - val_acc: 0.8974\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.3090e-06 - acc: 1.0000 - val_loss: 0.9245 - val_acc: 0.8974\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.5730e-07 - acc: 1.0000 - val_loss: 0.9003 - val_acc: 0.8974\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7.3710e-07 - acc: 1.0000 - val_loss: 0.8858 - val_acc: 0.8974\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.8909e-07 - acc: 1.0000 - val_loss: 0.9143 - val_acc: 0.8974\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.1723e-07 - acc: 1.0000 - val_loss: 0.8624 - val_acc: 0.9231\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3114e-07 - acc: 1.0000 - val_loss: 0.8936 - val_acc: 0.8974\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.2319e-07 - acc: 1.0000 - val_loss: 0.9072 - val_acc: 0.8974\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.7318e-07 - acc: 1.0000 - val_loss: 1.0404 - val_acc: 0.8974\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.7252e-07 - acc: 1.0000 - val_loss: 0.9102 - val_acc: 0.8974\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7.6824e-08 - acc: 1.0000 - val_loss: 0.8775 - val_acc: 0.9231\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 5.8611e-08 - acc: 1.0000 - val_loss: 0.8823 - val_acc: 0.8974\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.2717e-08 - acc: 1.0000 - val_loss: 0.8856 - val_acc: 0.8974\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.1127e-08 - acc: 1.0000 - val_loss: 0.8773 - val_acc: 0.9231\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.2848e-08 - acc: 1.0000 - val_loss: 0.8799 - val_acc: 0.9231\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.6557e-08 - acc: 1.0000 - val_loss: 0.9099 - val_acc: 0.9231\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.0928e-08 - acc: 1.0000 - val_loss: 0.8886 - val_acc: 0.9231\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.9407e-09 - acc: 1.0000 - val_loss: 0.8676 - val_acc: 0.9487\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4.6359e-09 - acc: 1.0000 - val_loss: 0.8421 - val_acc: 0.9487\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.9736e-09 - acc: 1.0000 - val_loss: 0.8471 - val_acc: 0.9487\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.9802e-09 - acc: 1.0000 - val_loss: 0.8659 - val_acc: 0.9487\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.9802e-09 - acc: 1.0000 - val_loss: 0.8836 - val_acc: 0.9487\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.6491e-09 - acc: 1.0000 - val_loss: 0.9284 - val_acc: 0.9231\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-09 - acc: 1.0000 - val_loss: 0.8698 - val_acc: 0.9487\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.3180e-09 - acc: 1.0000 - val_loss: 0.8772 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.9868e-09 - acc: 1.0000 - val_loss: 0.8844 - val_acc: 0.9487\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.6425e-09 - acc: 1.0000 - val_loss: 0.8988 - val_acc: 0.9231\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 6.2916e-09 - acc: 1.0000 - val_loss: 0.9694 - val_acc: 0.9231\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.2848e-08 - acc: 1.0000 - val_loss: 0.8642 - val_acc: 0.9487\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0714 - acc: 0.9861 - val_loss: 1.7892 - val_acc: 0.8205\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0136 - acc: 0.9944 - val_loss: 1.1501 - val_acc: 0.8974\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3105e-05 - acc: 1.0000 - val_loss: 1.1125 - val_acc: 0.8974\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.9804e-06 - acc: 1.0000 - val_loss: 1.1099 - val_acc: 0.8974\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.2294e-06 - acc: 1.0000 - val_loss: 1.0942 - val_acc: 0.9231\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.7728e-06 - acc: 1.0000 - val_loss: 1.0960 - val_acc: 0.8974\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.4842e-06 - acc: 1.0000 - val_loss: 1.1181 - val_acc: 0.8974\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.5655e-06 - acc: 1.0000 - val_loss: 1.0932 - val_acc: 0.8974\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.9056e-06 - acc: 1.0000 - val_loss: 1.0886 - val_acc: 0.8974\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3834e-06 - acc: 1.0000 - val_loss: 1.0962 - val_acc: 0.8974\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9.3445e-07 - acc: 1.0000 - val_loss: 1.0773 - val_acc: 0.9231\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.9438e-07 - acc: 1.0000 - val_loss: 1.0807 - val_acc: 0.8974\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 3.8080e-07 - acc: 1.0000 - val_loss: 1.0696 - val_acc: 0.9231\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.8080e-07 - acc: 1.0000 - val_loss: 1.0643 - val_acc: 0.9231\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.0497e-07 - acc: 1.0000 - val_loss: 1.0610 - val_acc: 0.9231\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.4769e-07 - acc: 1.0000 - val_loss: 1.0751 - val_acc: 0.9231\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0464e-07 - acc: 1.0000 - val_loss: 1.0401 - val_acc: 0.9487\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 6.6227e-08 - acc: 1.0000 - val_loss: 1.0395 - val_acc: 0.9231\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4.9008e-08 - acc: 1.0000 - val_loss: 1.0488 - val_acc: 0.9231\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.4438e-08 - acc: 1.0000 - val_loss: 1.0404 - val_acc: 0.9231\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.3511e-08 - acc: 1.0000 - val_loss: 1.0413 - val_acc: 0.9231\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.7219e-08 - acc: 1.0000 - val_loss: 1.0232 - val_acc: 0.9231\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0596e-08 - acc: 1.0000 - val_loss: 1.0038 - val_acc: 0.9487\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 7.2850e-09 - acc: 1.0000 - val_loss: 0.9840 - val_acc: 0.9487\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5.2982e-09 - acc: 1.0000 - val_loss: 0.9744 - val_acc: 0.9487\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.9736e-09 - acc: 1.0000 - val_loss: 0.9654 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.6491e-09 - acc: 1.0000 - val_loss: 0.9448 - val_acc: 0.9487\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.9868e-09 - acc: 1.0000 - val_loss: 0.9383 - val_acc: 0.9487\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 0.9345 - val_acc: 0.9487\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 0.9331 - val_acc: 0.9487\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9242 - val_acc: 0.9487\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9235 - val_acc: 0.9487\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9061 - val_acc: 0.9487\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9200 - val_acc: 0.9487\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.8312 - val_acc: 0.9487\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.6557e-09 - acc: 1.0000 - val_loss: 0.8697 - val_acc: 0.9487\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8663 - val_acc: 0.9487\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.8784 - val_acc: 0.9487\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3114e-09 - acc: 1.0000 - val_loss: 0.9535 - val_acc: 0.9231\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.8076 - acc: 0.9417 - val_loss: 1.3025 - val_acc: 0.8974\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3883e-04 - acc: 1.0000 - val_loss: 1.2610 - val_acc: 0.9231\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.1743e-05 - acc: 1.0000 - val_loss: 1.2349 - val_acc: 0.9231\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.7089e-05 - acc: 1.0000 - val_loss: 1.2140 - val_acc: 0.9231\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.4044e-05 - acc: 1.0000 - val_loss: 1.1949 - val_acc: 0.9231\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.6044e-05 - acc: 1.0000 - val_loss: 1.1790 - val_acc: 0.9231\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.1008e-05 - acc: 1.0000 - val_loss: 1.1617 - val_acc: 0.9231\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.3432e-06 - acc: 1.0000 - val_loss: 1.1448 - val_acc: 0.9231\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.9612e-06 - acc: 1.0000 - val_loss: 1.1307 - val_acc: 0.9231\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4796e-06 - acc: 1.0000 - val_loss: 1.1161 - val_acc: 0.9231\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.4317e-06 - acc: 1.0000 - val_loss: 1.1032 - val_acc: 0.9231\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.6924e-06 - acc: 1.0000 - val_loss: 1.0892 - val_acc: 0.9231\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.1546e-06 - acc: 1.0000 - val_loss: 1.0772 - val_acc: 0.9231\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.2286e-07 - acc: 1.0000 - val_loss: 1.0669 - val_acc: 0.9231\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.8313e-07 - acc: 1.0000 - val_loss: 1.0565 - val_acc: 0.9231\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4.1160e-07 - acc: 1.0000 - val_loss: 1.0465 - val_acc: 0.9231\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.8676e-07 - acc: 1.0000 - val_loss: 1.0351 - val_acc: 0.9231\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.9703e-07 - acc: 1.0000 - val_loss: 1.0261 - val_acc: 0.9231\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.4173e-07 - acc: 1.0000 - val_loss: 1.0182 - val_acc: 0.9231\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 1.0018 - val_acc: 0.9231\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 6.2254e-08 - acc: 1.0000 - val_loss: 1.0001 - val_acc: 0.9231\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.6690e-08 - acc: 1.0000 - val_loss: 0.9971 - val_acc: 0.9231\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.4107e-08 - acc: 1.0000 - val_loss: 0.9705 - val_acc: 0.9231\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.1855e-08 - acc: 1.0000 - val_loss: 0.9726 - val_acc: 0.9231\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.6557e-08 - acc: 1.0000 - val_loss: 0.9744 - val_acc: 0.9231\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.2914e-08 - acc: 1.0000 - val_loss: 0.9605 - val_acc: 0.9231\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.2784e-09 - acc: 1.0000 - val_loss: 0.9630 - val_acc: 0.9487\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.9605e-09 - acc: 1.0000 - val_loss: 0.9623 - val_acc: 0.9487\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.9671e-09 - acc: 1.0000 - val_loss: 0.9567 - val_acc: 0.9487\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.3180e-09 - acc: 1.0000 - val_loss: 0.9544 - val_acc: 0.9487\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 0.9464 - val_acc: 0.9487\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 0.9364 - val_acc: 0.9487\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 0.9303 - val_acc: 0.9487\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 0.9205 - val_acc: 0.9487\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 0.9428 - val_acc: 0.9487\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9271 - val_acc: 0.9487\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9307 - val_acc: 0.9487\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 0.8960 - val_acc: 0.9487\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 0.8986 - val_acc: 0.9231\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.6557e-09 - acc: 1.0000 - val_loss: 0.8027 - val_acc: 0.9487\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-09 - acc: 1.0000 - val_loss: 0.8543 - val_acc: 0.9487\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.8339 - val_acc: 0.9487\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.3245e-09 - acc: 1.0000 - val_loss: 0.7623 - val_acc: 0.9487\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0549 - acc: 0.9917 - val_loss: 1.8513 - val_acc: 0.8718\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1855 - acc: 0.9611 - val_loss: 1.1903 - val_acc: 0.8718\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.0927e-05 - acc: 1.0000 - val_loss: 1.1061 - val_acc: 0.8718\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.6815e-06 - acc: 1.0000 - val_loss: 1.1222 - val_acc: 0.8718\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.6051e-06 - acc: 1.0000 - val_loss: 1.1087 - val_acc: 0.8718\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4.6168e-06 - acc: 1.0000 - val_loss: 1.0918 - val_acc: 0.8974\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.7810e-06 - acc: 1.0000 - val_loss: 1.0582 - val_acc: 0.8974\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.0833e-06 - acc: 1.0000 - val_loss: 1.0477 - val_acc: 0.8974\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.4265e-06 - acc: 1.0000 - val_loss: 1.0184 - val_acc: 0.8974\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.9353e-06 - acc: 1.0000 - val_loss: 1.0094 - val_acc: 0.8974\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.5244e-06 - acc: 1.0000 - val_loss: 0.9752 - val_acc: 0.8974\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.3162e-06 - acc: 1.0000 - val_loss: 1.0523 - val_acc: 0.8974\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8.7482e-07 - acc: 1.0000 - val_loss: 1.0481 - val_acc: 0.8974\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.4570e-07 - acc: 1.0000 - val_loss: 1.0282 - val_acc: 0.8974\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.9040e-07 - acc: 1.0000 - val_loss: 1.0222 - val_acc: 0.8974\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.6193e-07 - acc: 1.0000 - val_loss: 0.9936 - val_acc: 0.8974\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.6160e-07 - acc: 1.0000 - val_loss: 0.9998 - val_acc: 0.8974\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.8477e-07 - acc: 1.0000 - val_loss: 1.0379 - val_acc: 0.8974\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.3212e-07 - acc: 1.0000 - val_loss: 0.9884 - val_acc: 0.8974\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.0400e-08 - acc: 1.0000 - val_loss: 1.0050 - val_acc: 0.9231\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 6.3909e-08 - acc: 1.0000 - val_loss: 0.9997 - val_acc: 0.9231\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.4703e-08 - acc: 1.0000 - val_loss: 0.9847 - val_acc: 0.9231\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.2120e-08 - acc: 1.0000 - val_loss: 0.9587 - val_acc: 0.9231\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.4835e-08 - acc: 1.0000 - val_loss: 1.0211 - val_acc: 0.9231\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.6557e-08 - acc: 1.0000 - val_loss: 0.9773 - val_acc: 0.9231\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0928e-08 - acc: 1.0000 - val_loss: 0.9750 - val_acc: 0.9231\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7.9473e-09 - acc: 1.0000 - val_loss: 0.9568 - val_acc: 0.9231\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4.9671e-09 - acc: 1.0000 - val_loss: 0.9750 - val_acc: 0.9231\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.6491e-09 - acc: 1.0000 - val_loss: 0.9687 - val_acc: 0.9231\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.9868e-09 - acc: 1.0000 - val_loss: 0.9545 - val_acc: 0.9487\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.6557e-09 - acc: 1.0000 - val_loss: 0.9543 - val_acc: 0.9487\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9503 - val_acc: 0.9487\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9461 - val_acc: 0.9487\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9369 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9301 - val_acc: 0.9231\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 0.9077 - val_acc: 0.9487\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9153 - val_acc: 0.9487\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9285 - val_acc: 0.9231\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9194 - val_acc: 0.9231\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 0.8857 - val_acc: 0.9487\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9179 - val_acc: 0.9231\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 0.8572 - val_acc: 0.9487\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 0.8890 - val_acc: 0.9487\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.3245e-09 - acc: 1.0000 - val_loss: 0.8671 - val_acc: 0.9231\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 0.8538 - val_acc: 0.9487\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4.9671e-09 - acc: 1.0000 - val_loss: 0.7951 - val_acc: 0.9487\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.4438e-08 - acc: 1.0000 - val_loss: 3.7108 - val_acc: 0.7692\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6730 - acc: 0.9278 - val_loss: 1.6485 - val_acc: 0.8974\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.6536e-05 - acc: 1.0000 - val_loss: 1.6380 - val_acc: 0.8974\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.1365e-05 - acc: 1.0000 - val_loss: 1.6284 - val_acc: 0.8974\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.7193e-05 - acc: 1.0000 - val_loss: 1.6189 - val_acc: 0.8974\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.3486e-05 - acc: 1.0000 - val_loss: 1.6080 - val_acc: 0.8974\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0579e-05 - acc: 1.0000 - val_loss: 1.5962 - val_acc: 0.8974\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.4293e-06 - acc: 1.0000 - val_loss: 1.5823 - val_acc: 0.8974\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.2480e-06 - acc: 1.0000 - val_loss: 1.5682 - val_acc: 0.8974\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4.6206e-06 - acc: 1.0000 - val_loss: 1.5531 - val_acc: 0.8974\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3130e-06 - acc: 1.0000 - val_loss: 1.5347 - val_acc: 0.8974\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.2817e-06 - acc: 1.0000 - val_loss: 1.5192 - val_acc: 0.8974\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.6824e-06 - acc: 1.0000 - val_loss: 1.5028 - val_acc: 0.8974\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.2315e-06 - acc: 1.0000 - val_loss: 1.4859 - val_acc: 0.8974\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.6259e-07 - acc: 1.0000 - val_loss: 1.4671 - val_acc: 0.8974\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.1359e-07 - acc: 1.0000 - val_loss: 1.4486 - val_acc: 0.8974\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.2915e-07 - acc: 1.0000 - val_loss: 1.4162 - val_acc: 0.8974\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.6789e-07 - acc: 1.0000 - val_loss: 1.3865 - val_acc: 0.8974\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.7683e-07 - acc: 1.0000 - val_loss: 1.3726 - val_acc: 0.8974\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.2550e-07 - acc: 1.0000 - val_loss: 1.3595 - val_acc: 0.8974\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.8082e-08 - acc: 1.0000 - val_loss: 1.3455 - val_acc: 0.8974\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.3909e-08 - acc: 1.0000 - val_loss: 1.3307 - val_acc: 0.8974\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.6690e-08 - acc: 1.0000 - val_loss: 1.3165 - val_acc: 0.8974\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.1789e-08 - acc: 1.0000 - val_loss: 1.2982 - val_acc: 0.8974\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.2186e-08 - acc: 1.0000 - val_loss: 1.2743 - val_acc: 0.8974\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.4239e-08 - acc: 1.0000 - val_loss: 1.2599 - val_acc: 0.8974\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9.2718e-09 - acc: 1.0000 - val_loss: 1.2483 - val_acc: 0.9231\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.9605e-09 - acc: 1.0000 - val_loss: 1.2426 - val_acc: 0.9231\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.3048e-09 - acc: 1.0000 - val_loss: 1.2233 - val_acc: 0.9231\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.9868e-09 - acc: 1.0000 - val_loss: 1.2102 - val_acc: 0.9231\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.3245e-09 - acc: 1.0000 - val_loss: 1.1962 - val_acc: 0.9231\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.3245e-09 - acc: 1.0000 - val_loss: 1.1660 - val_acc: 0.9231\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1572 - val_acc: 0.9231\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.1314 - val_acc: 0.9231\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1292 - val_acc: 0.9231\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1189 - val_acc: 0.9231\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.0835 - val_acc: 0.9231\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.0604 - val_acc: 0.9231\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 1.0471 - val_acc: 0.9231\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.0063 - val_acc: 0.9231\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0382 - val_acc: 0.9231\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 1.0044 - val_acc: 0.9231\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.0241 - val_acc: 0.9487\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.6557e-09 - acc: 1.0000 - val_loss: 1.0100 - val_acc: 0.9231\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 1.0198 - val_acc: 0.9231\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.9868e-09 - acc: 1.0000 - val_loss: 0.9530 - val_acc: 0.9231\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6045 - acc: 0.9472 - val_loss: 0.8275 - val_acc: 0.8974\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0043 - acc: 0.9972 - val_loss: 0.9178 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.8362e-05 - acc: 1.0000 - val_loss: 0.9323 - val_acc: 0.9487\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.3192e-05 - acc: 1.0000 - val_loss: 0.9445 - val_acc: 0.9487\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.8025e-06 - acc: 1.0000 - val_loss: 0.9566 - val_acc: 0.9487\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.1054e-06 - acc: 1.0000 - val_loss: 0.9698 - val_acc: 0.9487\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.0356e-06 - acc: 1.0000 - val_loss: 0.9828 - val_acc: 0.9487\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.7062e-06 - acc: 1.0000 - val_loss: 0.9967 - val_acc: 0.9487\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.5993e-06 - acc: 1.0000 - val_loss: 1.0100 - val_acc: 0.9487\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.7578e-06 - acc: 1.0000 - val_loss: 1.0219 - val_acc: 0.9487\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.2394e-06 - acc: 1.0000 - val_loss: 1.0523 - val_acc: 0.9487\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.4668e-07 - acc: 1.0000 - val_loss: 1.0695 - val_acc: 0.9487\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.2584e-07 - acc: 1.0000 - val_loss: 1.0703 - val_acc: 0.9487\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.5829e-07 - acc: 1.0000 - val_loss: 1.0715 - val_acc: 0.9487\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.0398e-07 - acc: 1.0000 - val_loss: 1.0742 - val_acc: 0.9487\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.6325e-07 - acc: 1.0000 - val_loss: 1.0784 - val_acc: 0.9487\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.2451e-07 - acc: 1.0000 - val_loss: 1.0822 - val_acc: 0.9487\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9.2387e-08 - acc: 1.0000 - val_loss: 1.0845 - val_acc: 0.9487\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 6.9870e-08 - acc: 1.0000 - val_loss: 1.0908 - val_acc: 0.9487\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.1326e-08 - acc: 1.0000 - val_loss: 1.1063 - val_acc: 0.9487\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.8412e-08 - acc: 1.0000 - val_loss: 1.1186 - val_acc: 0.9487\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.6822e-08 - acc: 1.0000 - val_loss: 1.1284 - val_acc: 0.9487\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.9206e-08 - acc: 1.0000 - val_loss: 1.1386 - val_acc: 0.9487\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3908e-08 - acc: 1.0000 - val_loss: 1.1542 - val_acc: 0.9487\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.0265e-08 - acc: 1.0000 - val_loss: 1.1368 - val_acc: 0.9487\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.6227e-09 - acc: 1.0000 - val_loss: 1.1500 - val_acc: 0.9487\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.9736e-09 - acc: 1.0000 - val_loss: 1.1701 - val_acc: 0.9487\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.3180e-09 - acc: 1.0000 - val_loss: 1.1796 - val_acc: 0.9487\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.3245e-09 - acc: 1.0000 - val_loss: 1.1822 - val_acc: 0.9487\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.1855 - val_acc: 0.9487\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 1.1891 - val_acc: 0.9487\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.1969 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.1959 - val_acc: 0.9487\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2080 - val_acc: 0.9487\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.2052 - val_acc: 0.9231\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2250 - val_acc: 0.9231\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 1.2262 - val_acc: 0.9231\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2385 - val_acc: 0.9231\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.2040 - val_acc: 0.9231\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.2518 - val_acc: 0.9231\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.3180e-09 - acc: 1.0000 - val_loss: 1.2041 - val_acc: 0.9231\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9.0730e-08 - acc: 1.0000 - val_loss: 3.8692 - val_acc: 0.7692\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1364 - acc: 0.9778 - val_loss: 1.4592 - val_acc: 0.8718\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4.2795e-05 - acc: 1.0000 - val_loss: 1.4023 - val_acc: 0.8718\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.0980e-05 - acc: 1.0000 - val_loss: 1.3680 - val_acc: 0.8974\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3201e-05 - acc: 1.0000 - val_loss: 1.3363 - val_acc: 0.8974\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8.3861e-06 - acc: 1.0000 - val_loss: 1.3046 - val_acc: 0.8974\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.1813e-06 - acc: 1.0000 - val_loss: 1.2811 - val_acc: 0.8974\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 3.7567e-06 - acc: 1.0000 - val_loss: 1.2588 - val_acc: 0.8974\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.6714e-06 - acc: 1.0000 - val_loss: 1.2312 - val_acc: 0.8974\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.7834e-06 - acc: 1.0000 - val_loss: 1.2073 - val_acc: 0.9231\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.2536e-06 - acc: 1.0000 - val_loss: 1.1855 - val_acc: 0.9231\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.8677e-07 - acc: 1.0000 - val_loss: 1.1444 - val_acc: 0.9231\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5.6789e-07 - acc: 1.0000 - val_loss: 1.1276 - val_acc: 0.9231\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.0465e-07 - acc: 1.0000 - val_loss: 1.1107 - val_acc: 0.9231\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.8445e-07 - acc: 1.0000 - val_loss: 1.0819 - val_acc: 0.9231\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.8974e-07 - acc: 1.0000 - val_loss: 1.0677 - val_acc: 0.9231\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.3345e-07 - acc: 1.0000 - val_loss: 1.0586 - val_acc: 0.9231\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 9.6361e-08 - acc: 1.0000 - val_loss: 1.0458 - val_acc: 0.9231\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.1591e-08 - acc: 1.0000 - val_loss: 1.0417 - val_acc: 0.9231\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.5035e-08 - acc: 1.0000 - val_loss: 1.0354 - val_acc: 0.9487\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.1789e-08 - acc: 1.0000 - val_loss: 1.0161 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.1855e-08 - acc: 1.0000 - val_loss: 1.0279 - val_acc: 0.9487\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.5563e-08 - acc: 1.0000 - val_loss: 1.0223 - val_acc: 0.9487\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.0596e-08 - acc: 1.0000 - val_loss: 1.0250 - val_acc: 0.9487\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 2.3842e-09 - acc: 1.000 - 0s 5ms/step - loss: 6.6227e-09 - acc: 1.0000 - val_loss: 1.0299 - val_acc: 0.9487\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.3048e-09 - acc: 1.0000 - val_loss: 1.0345 - val_acc: 0.9487\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.6425e-09 - acc: 1.0000 - val_loss: 1.0289 - val_acc: 0.9487\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.3180e-09 - acc: 1.0000 - val_loss: 1.0425 - val_acc: 0.9487\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.6557e-09 - acc: 1.0000 - val_loss: 1.0291 - val_acc: 0.9487\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 1.0554 - val_acc: 0.9487\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.0383 - val_acc: 0.9487\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.0288 - val_acc: 0.9487\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.0178 - val_acc: 0.9487\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0202 - val_acc: 0.9487\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0227 - val_acc: 0.9487\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0257 - val_acc: 0.9487\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0316 - val_acc: 0.9487\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.0342 - val_acc: 0.9487\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.0075 - val_acc: 0.9487\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0112 - val_acc: 0.9487\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0111 - val_acc: 0.9487\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0194 - val_acc: 0.9487\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0287 - val_acc: 0.9487\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0379 - val_acc: 0.9487\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0461 - val_acc: 0.9487\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0503 - val_acc: 0.9487\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.0542 - val_acc: 0.9487\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 0.9643 - val_acc: 0.9487\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.6557e-09 - acc: 1.0000 - val_loss: 0.9854 - val_acc: 0.9487\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9952 - val_acc: 0.9487\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0073 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 0.9960 - val_acc: 0.9487\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0928e-08 - acc: 1.0000 - val_loss: 2.2725 - val_acc: 0.8718\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1531 - acc: 0.9778 - val_loss: 0.9569 - val_acc: 0.9231\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.5644e-05 - acc: 1.0000 - val_loss: 1.0087 - val_acc: 0.9231\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.1975e-06 - acc: 1.0000 - val_loss: 1.0045 - val_acc: 0.9231\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3386e-06 - acc: 1.0000 - val_loss: 1.0073 - val_acc: 0.9231\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.8544e-06 - acc: 1.0000 - val_loss: 0.9999 - val_acc: 0.9231\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.4298e-06 - acc: 1.0000 - val_loss: 0.9974 - val_acc: 0.9231\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.9857e-06 - acc: 1.0000 - val_loss: 0.9989 - val_acc: 0.9231\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.5673e-06 - acc: 1.0000 - val_loss: 1.0053 - val_acc: 0.9231\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.1986e-06 - acc: 1.0000 - val_loss: 1.0118 - val_acc: 0.9231\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 8.5725e-07 - acc: 1.0000 - val_loss: 1.0211 - val_acc: 0.9231\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5.9469e-07 - acc: 1.0000 - val_loss: 1.0238 - val_acc: 0.9231\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.2748e-07 - acc: 1.0000 - val_loss: 1.0356 - val_acc: 0.9231\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.0067e-07 - acc: 1.0000 - val_loss: 1.0345 - val_acc: 0.9231\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.2385e-07 - acc: 1.0000 - val_loss: 1.0474 - val_acc: 0.8974\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.6325e-07 - acc: 1.0000 - val_loss: 1.0112 - val_acc: 0.9231\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.4272e-07 - acc: 1.0000 - val_loss: 1.0455 - val_acc: 0.9231\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.6293e-08 - acc: 1.0000 - val_loss: 1.0610 - val_acc: 0.9231\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.8081e-08 - acc: 1.0000 - val_loss: 1.0586 - val_acc: 0.9231\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.6822e-08 - acc: 1.0000 - val_loss: 1.0551 - val_acc: 0.9231\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.0530e-08 - acc: 1.0000 - val_loss: 1.0749 - val_acc: 0.9231\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.4901e-08 - acc: 1.0000 - val_loss: 1.0718 - val_acc: 0.9231\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.1590e-08 - acc: 1.0000 - val_loss: 1.0689 - val_acc: 0.9231\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.9539e-09 - acc: 1.0000 - val_loss: 1.0918 - val_acc: 0.9231\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.9605e-09 - acc: 1.0000 - val_loss: 1.0770 - val_acc: 0.9231\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.6425e-09 - acc: 1.0000 - val_loss: 1.0643 - val_acc: 0.9231\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.3180e-09 - acc: 1.0000 - val_loss: 1.0577 - val_acc: 0.9231\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.6557e-09 - acc: 1.0000 - val_loss: 1.0485 - val_acc: 0.9231\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 1.0458 - val_acc: 0.9231\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 1.0398 - val_acc: 0.9231\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0456 - val_acc: 0.9231\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0495 - val_acc: 0.9231\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0426 - val_acc: 0.9231\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0397 - val_acc: 0.9231\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0394 - val_acc: 0.9231\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0391 - val_acc: 0.9231\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0387 - val_acc: 0.9231\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0471 - val_acc: 0.9231\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0465 - val_acc: 0.9231\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0468 - val_acc: 0.9231\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0468 - val_acc: 0.9231\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0468 - val_acc: 0.9231\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0407 - val_acc: 0.9231\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0425 - val_acc: 0.9231\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0438 - val_acc: 0.9231\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0462 - val_acc: 0.9231\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0485 - val_acc: 0.9231\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0554 - val_acc: 0.9231\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0571 - val_acc: 0.9231\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0575 - val_acc: 0.9231\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0638 - val_acc: 0.9231\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0671 - val_acc: 0.9231\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0663 - val_acc: 0.9231\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0689 - val_acc: 0.9231\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0728 - val_acc: 0.9231\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0885 - val_acc: 0.9231\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 1.0650 - val_acc: 0.9487\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 1.0405 - val_acc: 0.9231\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5823 - acc: 0.9444 - val_loss: 1.5205 - val_acc: 0.8974\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 9.7881e-05 - acc: 1.0000 - val_loss: 1.4960 - val_acc: 0.8974\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.2347e-05 - acc: 1.0000 - val_loss: 1.4855 - val_acc: 0.8974\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.9939e-05 - acc: 1.0000 - val_loss: 1.4759 - val_acc: 0.8974\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.3134e-05 - acc: 1.0000 - val_loss: 1.4665 - val_acc: 0.8974\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 8.3827e-06 - acc: 1.0000 - val_loss: 1.4573 - val_acc: 0.8974\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5.7526e-06 - acc: 1.0000 - val_loss: 1.4444 - val_acc: 0.8974\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.6993e-06 - acc: 1.0000 - val_loss: 1.4343 - val_acc: 0.8974\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.6017e-06 - acc: 1.0000 - val_loss: 1.4242 - val_acc: 0.8974\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.8625e-06 - acc: 1.0000 - val_loss: 1.4139 - val_acc: 0.8974\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.2884e-06 - acc: 1.0000 - val_loss: 1.4026 - val_acc: 0.8974\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.1456e-07 - acc: 1.0000 - val_loss: 1.3895 - val_acc: 0.8974\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.2385e-07 - acc: 1.0000 - val_loss: 1.3741 - val_acc: 0.8974\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.3743e-07 - acc: 1.0000 - val_loss: 1.3561 - val_acc: 0.8974\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.8974e-07 - acc: 1.0000 - val_loss: 1.3379 - val_acc: 0.8974\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.1524e-07 - acc: 1.0000 - val_loss: 1.3223 - val_acc: 0.8974\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.5000e-07 - acc: 1.0000 - val_loss: 1.3027 - val_acc: 0.8974\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0133e-07 - acc: 1.0000 - val_loss: 1.2857 - val_acc: 0.8974\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.7883e-08 - acc: 1.0000 - val_loss: 1.2561 - val_acc: 0.9231\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.0067e-08 - acc: 1.0000 - val_loss: 1.2464 - val_acc: 0.9231\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 3.0133e-08 - acc: 1.0000 - val_loss: 1.2295 - val_acc: 0.9231\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.0862e-08 - acc: 1.0000 - val_loss: 1.2228 - val_acc: 0.9231\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.5232e-08 - acc: 1.0000 - val_loss: 1.2126 - val_acc: 0.9231\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0928e-08 - acc: 1.0000 - val_loss: 1.2009 - val_acc: 0.9231\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 6.6227e-09 - acc: 1.0000 - val_loss: 1.1818 - val_acc: 0.9231\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 5.6293e-09 - acc: 1.0000 - val_loss: 1.1738 - val_acc: 0.9231\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.9736e-09 - acc: 1.0000 - val_loss: 1.1688 - val_acc: 0.9231\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.9868e-09 - acc: 1.0000 - val_loss: 1.1616 - val_acc: 0.9231\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 1.1585 - val_acc: 0.9231\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 1.1559 - val_acc: 0.9231\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 1.1555 - val_acc: 0.9231\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1457 - val_acc: 0.9231\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1355 - val_acc: 0.9231\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1274 - val_acc: 0.9231\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1202 - val_acc: 0.9231\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1133 - val_acc: 0.9231\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1092 - val_acc: 0.9231\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1055 - val_acc: 0.9231\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1035 - val_acc: 0.9231\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1021 - val_acc: 0.9231\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1014 - val_acc: 0.9231\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1027 - val_acc: 0.9231\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1035 - val_acc: 0.9231\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1045 - val_acc: 0.9231\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1021 - val_acc: 0.9231\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1029 - val_acc: 0.9231\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1022 - val_acc: 0.9231\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0997 - val_acc: 0.9231\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1023 - val_acc: 0.8974\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1079 - val_acc: 0.9231\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.1218 - val_acc: 0.9231\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3908e-08 - acc: 1.0000 - val_loss: 1.0074 - val_acc: 0.8974\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3923 - acc: 0.9667 - val_loss: 0.9240 - val_acc: 0.8974\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0054 - acc: 0.9972 - val_loss: 1.5225 - val_acc: 0.9487\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4380e-05 - acc: 1.0000 - val_loss: 1.4948 - val_acc: 0.9487\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.0497e-05 - acc: 1.0000 - val_loss: 1.4862 - val_acc: 0.9487\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 6.7998e-06 - acc: 1.0000 - val_loss: 1.4765 - val_acc: 0.9487\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4.0127e-06 - acc: 1.0000 - val_loss: 1.4678 - val_acc: 0.9487\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.5349e-06 - acc: 1.0000 - val_loss: 1.4578 - val_acc: 0.9487\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.6613e-06 - acc: 1.0000 - val_loss: 1.4483 - val_acc: 0.9487\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.1108e-06 - acc: 1.0000 - val_loss: 1.4372 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 7.0592e-07 - acc: 1.0000 - val_loss: 1.4254 - val_acc: 0.9487\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4.7251e-07 - acc: 1.0000 - val_loss: 1.4146 - val_acc: 0.9487\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.4271e-07 - acc: 1.0000 - val_loss: 1.4023 - val_acc: 0.9487\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.2451e-07 - acc: 1.0000 - val_loss: 1.3909 - val_acc: 0.9487\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.5365e-07 - acc: 1.0000 - val_loss: 1.3778 - val_acc: 0.9487\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.0828e-07 - acc: 1.0000 - val_loss: 1.3618 - val_acc: 0.9487\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.5896e-08 - acc: 1.0000 - val_loss: 1.3485 - val_acc: 0.9487\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.5366e-08 - acc: 1.0000 - val_loss: 1.3370 - val_acc: 0.9487\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.2451e-08 - acc: 1.0000 - val_loss: 1.3239 - val_acc: 0.9487\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.2848e-08 - acc: 1.0000 - val_loss: 1.3114 - val_acc: 0.9487\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.5232e-08 - acc: 1.0000 - val_loss: 1.2983 - val_acc: 0.9487\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.1259e-08 - acc: 1.0000 - val_loss: 1.2865 - val_acc: 0.9487\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.9539e-09 - acc: 1.0000 - val_loss: 1.2767 - val_acc: 0.9487\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5.2982e-09 - acc: 1.0000 - val_loss: 1.2659 - val_acc: 0.9487\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.9736e-09 - acc: 1.0000 - val_loss: 1.2561 - val_acc: 0.9487\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.3180e-09 - acc: 1.0000 - val_loss: 1.2487 - val_acc: 0.9487\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6557e-09 - acc: 1.0000 - val_loss: 1.2401 - val_acc: 0.9487\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.6557e-09 - acc: 1.0000 - val_loss: 1.2315 - val_acc: 0.9487\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 1.2227 - val_acc: 0.9487\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.2123 - val_acc: 0.9487\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.2059 - val_acc: 0.9487\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2044 - val_acc: 0.9487\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2044 - val_acc: 0.9487\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2031 - val_acc: 0.9487\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2025 - val_acc: 0.9487\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2022 - val_acc: 0.9487\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1973 - val_acc: 0.9487\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1979 - val_acc: 0.9487\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1995 - val_acc: 0.9487\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2003 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1993 - val_acc: 0.9487\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1991 - val_acc: 0.9487\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1959 - val_acc: 0.9487\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1944 - val_acc: 0.9487\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1933 - val_acc: 0.9487\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1921 - val_acc: 0.9487\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1984 - val_acc: 0.9487\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2010 - val_acc: 0.9487\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2019 - val_acc: 0.9487\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2130 - val_acc: 0.9487\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2161 - val_acc: 0.9487\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2231 - val_acc: 0.9487\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2287 - val_acc: 0.9487\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2412 - val_acc: 0.9487\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.2521 - val_acc: 0.9487\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2417 - val_acc: 0.9487\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 1.2547 - val_acc: 0.9231\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.2032 - val_acc: 0.9487\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.6491e-09 - acc: 1.0000 - val_loss: 1.1801 - val_acc: 0.9487\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 1.1681 - val_acc: 0.9487\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.2125 - val_acc: 0.9231\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.9802e-09 - acc: 1.0000 - val_loss: 1.1690 - val_acc: 0.9487\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.3245e-09 - acc: 1.0000 - val_loss: 1.1102 - val_acc: 0.9487\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 1.1495 - val_acc: 0.9231\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.3180e-09 - acc: 1.0000 - val_loss: 1.1054 - val_acc: 0.9487\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.8115 - acc: 0.9361 - val_loss: 1.5588 - val_acc: 0.9231\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0043 - acc: 0.9972 - val_loss: 1.1911 - val_acc: 0.9487\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.8824e-05 - acc: 1.0000 - val_loss: 1.3875 - val_acc: 0.9487\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.4528e-05 - acc: 1.0000 - val_loss: 1.3750 - val_acc: 0.9487\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.1230e-05 - acc: 1.0000 - val_loss: 1.3639 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 8.6593e-06 - acc: 1.0000 - val_loss: 1.3573 - val_acc: 0.9487\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.4333e-06 - acc: 1.0000 - val_loss: 1.3592 - val_acc: 0.9487\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.8352e-06 - acc: 1.0000 - val_loss: 1.3512 - val_acc: 0.9487\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.5596e-06 - acc: 1.0000 - val_loss: 1.3391 - val_acc: 0.9487\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.7445e-06 - acc: 1.0000 - val_loss: 1.3743 - val_acc: 0.9487\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.0874e-06 - acc: 1.0000 - val_loss: 1.3451 - val_acc: 0.9487\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.6265e-06 - acc: 1.0000 - val_loss: 1.3471 - val_acc: 0.9487\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.2116e-06 - acc: 1.0000 - val_loss: 1.3696 - val_acc: 0.9487\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.3279e-07 - acc: 1.0000 - val_loss: 1.3188 - val_acc: 0.9487\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.7716e-07 - acc: 1.0000 - val_loss: 1.3606 - val_acc: 0.9487\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5.0266e-07 - acc: 1.0000 - val_loss: 1.3708 - val_acc: 0.9487\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.6723e-07 - acc: 1.0000 - val_loss: 1.3760 - val_acc: 0.9487\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.5762e-07 - acc: 1.0000 - val_loss: 1.3794 - val_acc: 0.9487\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.8014e-07 - acc: 1.0000 - val_loss: 1.3828 - val_acc: 0.9487\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.6722e-07 - acc: 1.0000 - val_loss: 1.3534 - val_acc: 0.9487\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 6.7552e-08 - acc: 1.0000 - val_loss: 1.3527 - val_acc: 0.9487\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.0002e-08 - acc: 1.0000 - val_loss: 1.3506 - val_acc: 0.9487\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.6425e-08 - acc: 1.0000 - val_loss: 1.3482 - val_acc: 0.9487\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4504e-08 - acc: 1.0000 - val_loss: 1.3437 - val_acc: 0.9487\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.5895e-08 - acc: 1.0000 - val_loss: 1.3403 - val_acc: 0.9487\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.2914e-08 - acc: 1.0000 - val_loss: 1.3369 - val_acc: 0.9487\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.9407e-09 - acc: 1.0000 - val_loss: 1.3479 - val_acc: 0.9487\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5.6293e-09 - acc: 1.0000 - val_loss: 1.3258 - val_acc: 0.9487\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.9802e-09 - acc: 1.0000 - val_loss: 1.3251 - val_acc: 0.9487\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.9868e-09 - acc: 1.0000 - val_loss: 1.3209 - val_acc: 0.9487\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.6557e-09 - acc: 1.0000 - val_loss: 1.3197 - val_acc: 0.9487\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.3170 - val_acc: 0.9487\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 1.3192 - val_acc: 0.9487\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 1.3144 - val_acc: 0.9487\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 1.3084 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.3023 - val_acc: 0.9487\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.2780 - val_acc: 0.9487\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2884 - val_acc: 0.9487\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2831 - val_acc: 0.9487\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 1.2604 - val_acc: 0.9487\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3414 - acc: 0.9583 - val_loss: 1.7359 - val_acc: 0.8974\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0126 - acc: 0.9944 - val_loss: 1.5315 - val_acc: 0.9231\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.2054e-08 - acc: 1.0000 - val_loss: 1.5318 - val_acc: 0.9231\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.7750e-08 - acc: 1.0000 - val_loss: 1.5320 - val_acc: 0.9231\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4769e-08 - acc: 1.0000 - val_loss: 1.5321 - val_acc: 0.9231\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.2120e-08 - acc: 1.0000 - val_loss: 1.5323 - val_acc: 0.9231\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.0465e-08 - acc: 1.0000 - val_loss: 1.5323 - val_acc: 0.9231\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.9140e-08 - acc: 1.0000 - val_loss: 1.5322 - val_acc: 0.9231\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.7484e-08 - acc: 1.0000 - val_loss: 1.5320 - val_acc: 0.9231\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.5498e-08 - acc: 1.0000 - val_loss: 1.5316 - val_acc: 0.9231\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.4504e-08 - acc: 1.0000 - val_loss: 1.5309 - val_acc: 0.9231\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.2517e-08 - acc: 1.0000 - val_loss: 1.5298 - val_acc: 0.9231\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.1193e-08 - acc: 1.0000 - val_loss: 1.5282 - val_acc: 0.9231\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.9206e-08 - acc: 1.0000 - val_loss: 1.5258 - val_acc: 0.9231\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.7550e-08 - acc: 1.0000 - val_loss: 1.5229 - val_acc: 0.9231\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.6888e-08 - acc: 1.0000 - val_loss: 1.5190 - val_acc: 0.9231\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.4901e-08 - acc: 1.0000 - val_loss: 1.5145 - val_acc: 0.9231\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.3908e-08 - acc: 1.0000 - val_loss: 1.5086 - val_acc: 0.9231\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0928e-08 - acc: 1.0000 - val_loss: 1.5023 - val_acc: 0.9231\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0596e-08 - acc: 1.0000 - val_loss: 1.4944 - val_acc: 0.9231\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9.2718e-09 - acc: 1.0000 - val_loss: 1.4838 - val_acc: 0.9231\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.2850e-09 - acc: 1.0000 - val_loss: 1.4732 - val_acc: 0.9231\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.6227e-09 - acc: 1.0000 - val_loss: 1.4601 - val_acc: 0.9231\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.9671e-09 - acc: 1.0000 - val_loss: 1.4460 - val_acc: 0.9231\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.9736e-09 - acc: 1.0000 - val_loss: 1.4330 - val_acc: 0.9231\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.9802e-09 - acc: 1.0000 - val_loss: 1.4142 - val_acc: 0.9231\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.3180e-09 - acc: 1.0000 - val_loss: 1.3939 - val_acc: 0.9231\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3245e-09 - acc: 1.0000 - val_loss: 1.3819 - val_acc: 0.9231\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 1.3636 - val_acc: 0.9231\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.3537 - val_acc: 0.9231\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.3439 - val_acc: 0.9231\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.3388 - val_acc: 0.9231\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.3291 - val_acc: 0.9231\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.3173 - val_acc: 0.9231\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2957 - val_acc: 0.9487\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2917 - val_acc: 0.9487\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2879 - val_acc: 0.9487\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2842 - val_acc: 0.9487\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2855 - val_acc: 0.9487\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2826 - val_acc: 0.9487\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2790 - val_acc: 0.9487\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2775 - val_acc: 0.9487\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2758 - val_acc: 0.9487\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2738 - val_acc: 0.9487\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2709 - val_acc: 0.9487\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2686 - val_acc: 0.9487\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2676 - val_acc: 0.9487\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2661 - val_acc: 0.9487\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2637 - val_acc: 0.9487\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2629 - val_acc: 0.9487\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2629 - val_acc: 0.9487\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2634 - val_acc: 0.9487\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2643 - val_acc: 0.9487\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2571 - val_acc: 0.9487\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2686 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 1.2751 - val_acc: 0.9487\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2672 - val_acc: 0.9487\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2589 - val_acc: 0.9487\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.2522 - val_acc: 0.9487\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.1808 - val_acc: 0.9487\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1831 - val_acc: 0.9487\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.6491e-09 - acc: 1.0000 - val_loss: 1.1530 - val_acc: 0.9487\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 1.0795 - val_acc: 0.9487\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4234 - acc: 0.9694 - val_loss: 1.9479 - val_acc: 0.8718\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.0841 - val_acc: 0.9487\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.9125e-06 - acc: 1.0000 - val_loss: 1.0841 - val_acc: 0.9487\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.4172e-06 - acc: 1.0000 - val_loss: 1.0839 - val_acc: 0.9487\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.2662e-06 - acc: 1.0000 - val_loss: 1.0837 - val_acc: 0.9487\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.1268e-06 - acc: 1.0000 - val_loss: 1.0836 - val_acc: 0.9487\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0175e-06 - acc: 1.0000 - val_loss: 1.0858 - val_acc: 0.9487\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.4821e-06 - acc: 1.0000 - val_loss: 1.0861 - val_acc: 0.9487\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 7.2021e-07 - acc: 1.0000 - val_loss: 1.0866 - val_acc: 0.9487\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.5266e-07 - acc: 1.0000 - val_loss: 1.0874 - val_acc: 0.9487\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.5564e-07 - acc: 1.0000 - val_loss: 1.0866 - val_acc: 0.9487\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.4901e-07 - acc: 1.0000 - val_loss: 1.0866 - val_acc: 0.9487\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.6226e-07 - acc: 1.0000 - val_loss: 1.0873 - val_acc: 0.9487\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.5862e-07 - acc: 1.0000 - val_loss: 1.0861 - val_acc: 0.9487\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.8246e-07 - acc: 1.0000 - val_loss: 1.0891 - val_acc: 0.9487\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.1756e-07 - acc: 1.0000 - val_loss: 1.0957 - val_acc: 0.9487\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8.1791e-08 - acc: 1.0000 - val_loss: 1.0957 - val_acc: 0.9487\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5.6955e-08 - acc: 1.0000 - val_loss: 1.0923 - val_acc: 0.9487\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.9074e-08 - acc: 1.0000 - val_loss: 1.0907 - val_acc: 0.9487\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.1789e-08 - acc: 1.0000 - val_loss: 1.0825 - val_acc: 0.9487\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.3511e-08 - acc: 1.0000 - val_loss: 1.0797 - val_acc: 0.9487\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.7550e-08 - acc: 1.0000 - val_loss: 1.0809 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.4901e-08 - acc: 1.0000 - val_loss: 1.0956 - val_acc: 0.9487\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.9341e-09 - acc: 1.0000 - val_loss: 1.0834 - val_acc: 0.9487\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.6030e-09 - acc: 1.0000 - val_loss: 1.0795 - val_acc: 0.9487\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.3048e-09 - acc: 1.0000 - val_loss: 1.0732 - val_acc: 0.9487\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.3180e-09 - acc: 1.0000 - val_loss: 1.0703 - val_acc: 0.9487\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.6557e-09 - acc: 1.0000 - val_loss: 1.0569 - val_acc: 0.9487\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 1.0541 - val_acc: 0.9487\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 1.0411 - val_acc: 0.9487\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 1.0318 - val_acc: 0.9487\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 1.0262 - val_acc: 0.9487\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.0146 - val_acc: 0.9487\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0024 - val_acc: 0.9487\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9956 - val_acc: 0.9487\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9882 - val_acc: 0.9487\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9889 - val_acc: 0.9487\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9961 - val_acc: 0.9487\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9825 - val_acc: 0.9487\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9755 - val_acc: 0.9487\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9700 - val_acc: 0.9487\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9691 - val_acc: 0.9487\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9661 - val_acc: 0.9487\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9691 - val_acc: 0.9487\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9676 - val_acc: 0.9487\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9915 - val_acc: 0.9487\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9983 - val_acc: 0.9487\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9939 - val_acc: 0.9487\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0052 - val_acc: 0.9487\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0076 - val_acc: 0.9487\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0085 - val_acc: 0.9487\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0057 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0131 - val_acc: 0.9487\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0112 - val_acc: 0.9487\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0100 - val_acc: 0.9487\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0089 - val_acc: 0.9487\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0067 - val_acc: 0.9487\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0060 - val_acc: 0.9487\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0052 - val_acc: 0.9487\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0056 - val_acc: 0.9487\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0081 - val_acc: 0.9487\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0126 - val_acc: 0.9487\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0180 - val_acc: 0.9487\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0266 - val_acc: 0.9487\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0905 - val_acc: 0.9487\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5799 - acc: 0.9528 - val_loss: 1.5697 - val_acc: 0.8462\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0249 - acc: 0.9889 - val_loss: 0.8059 - val_acc: 0.9231\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.2360e-05 - acc: 1.0000 - val_loss: 0.7846 - val_acc: 0.9231\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.4721e-05 - acc: 1.0000 - val_loss: 0.7781 - val_acc: 0.9231\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.7724e-06 - acc: 1.0000 - val_loss: 0.7714 - val_acc: 0.9231\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.6765e-06 - acc: 1.0000 - val_loss: 0.7658 - val_acc: 0.9231\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.5156e-06 - acc: 1.0000 - val_loss: 0.7603 - val_acc: 0.9231\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.2916e-06 - acc: 1.0000 - val_loss: 0.7549 - val_acc: 0.9231\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.2108e-06 - acc: 1.0000 - val_loss: 0.7419 - val_acc: 0.9231\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.1745e-06 - acc: 1.0000 - val_loss: 0.7388 - val_acc: 0.9231\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.9802e-07 - acc: 1.0000 - val_loss: 0.7308 - val_acc: 0.9231\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.9968e-07 - acc: 1.0000 - val_loss: 0.7292 - val_acc: 0.9231\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.3544e-07 - acc: 1.0000 - val_loss: 0.7314 - val_acc: 0.9231\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.2418e-07 - acc: 1.0000 - val_loss: 0.7346 - val_acc: 0.9231\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.4007e-07 - acc: 1.0000 - val_loss: 0.7251 - val_acc: 0.9231\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.8709e-07 - acc: 1.0000 - val_loss: 0.7288 - val_acc: 0.9231\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.5795e-07 - acc: 1.0000 - val_loss: 0.7204 - val_acc: 0.9231\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.4338e-07 - acc: 1.0000 - val_loss: 0.7168 - val_acc: 0.9487\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.8545e-08 - acc: 1.0000 - val_loss: 0.7118 - val_acc: 0.9487\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.8677e-08 - acc: 1.0000 - val_loss: 0.7169 - val_acc: 0.9231\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.5100e-08 - acc: 1.0000 - val_loss: 0.7101 - val_acc: 0.9231\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.4835e-08 - acc: 1.0000 - val_loss: 0.7054 - val_acc: 0.9487\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.7550e-08 - acc: 1.0000 - val_loss: 0.6987 - val_acc: 0.9487\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.1921e-08 - acc: 1.0000 - val_loss: 0.7072 - val_acc: 0.9231\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.2784e-09 - acc: 1.0000 - val_loss: 0.7009 - val_acc: 0.9231\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.6227e-09 - acc: 1.0000 - val_loss: 0.6959 - val_acc: 0.9231\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.6425e-09 - acc: 1.0000 - val_loss: 0.6930 - val_acc: 0.9231\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.6491e-09 - acc: 1.0000 - val_loss: 0.6903 - val_acc: 0.9231\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.3180e-09 - acc: 1.0000 - val_loss: 0.6904 - val_acc: 0.9231\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 0.6840 - val_acc: 0.9231\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 0.6785 - val_acc: 0.9231\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.6761 - val_acc: 0.9231\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.6758 - val_acc: 0.9231\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.6682 - val_acc: 0.9231\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.6709 - val_acc: 0.9231\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.6647 - val_acc: 0.9487\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.6637 - val_acc: 0.9487\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.6684 - val_acc: 0.9487\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.6727 - val_acc: 0.9487\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.6759 - val_acc: 0.9487\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.6799 - val_acc: 0.9487\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.6843 - val_acc: 0.9487\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.6906 - val_acc: 0.9487\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.6954 - val_acc: 0.9487\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7059 - val_acc: 0.9487\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7088 - val_acc: 0.9487\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7135 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7276 - val_acc: 0.9487\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7358 - val_acc: 0.9487\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.8553 - val_acc: 0.9487\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.8451 - acc: 0.9306 - val_loss: 1.1941 - val_acc: 0.9231\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.0751e-04 - acc: 1.0000 - val_loss: 1.1284 - val_acc: 0.9231\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.5825e-05 - acc: 1.0000 - val_loss: 1.1267 - val_acc: 0.9231\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.7352e-05 - acc: 1.0000 - val_loss: 1.1175 - val_acc: 0.9231\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3253e-05 - acc: 1.0000 - val_loss: 1.1079 - val_acc: 0.9231\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.6177e-06 - acc: 1.0000 - val_loss: 1.0982 - val_acc: 0.9231\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.6599e-06 - acc: 1.0000 - val_loss: 1.0827 - val_acc: 0.9231\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.4357e-06 - acc: 1.0000 - val_loss: 1.0727 - val_acc: 0.9231\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.0507e-06 - acc: 1.0000 - val_loss: 1.0634 - val_acc: 0.9231\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.1251e-06 - acc: 1.0000 - val_loss: 1.0542 - val_acc: 0.9231\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.4665e-06 - acc: 1.0000 - val_loss: 1.0438 - val_acc: 0.9231\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0361e-06 - acc: 1.0000 - val_loss: 1.0385 - val_acc: 0.9231\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.6855e-07 - acc: 1.0000 - val_loss: 1.0312 - val_acc: 0.9231\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.1624e-07 - acc: 1.0000 - val_loss: 1.0245 - val_acc: 0.9231\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.8974e-07 - acc: 1.0000 - val_loss: 1.0153 - val_acc: 0.9231\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.8676e-07 - acc: 1.0000 - val_loss: 1.0093 - val_acc: 0.9231\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.8775e-07 - acc: 1.0000 - val_loss: 1.0034 - val_acc: 0.9231\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.3974e-07 - acc: 1.0000 - val_loss: 0.9954 - val_acc: 0.9231\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.0298e-07 - acc: 1.0000 - val_loss: 0.9612 - val_acc: 0.9231\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 6.4903e-08 - acc: 1.0000 - val_loss: 0.9668 - val_acc: 0.9231\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4.5035e-08 - acc: 1.0000 - val_loss: 0.9625 - val_acc: 0.9231\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.4107e-08 - acc: 1.0000 - val_loss: 0.9612 - val_acc: 0.9231\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.5829e-08 - acc: 1.0000 - val_loss: 0.9587 - val_acc: 0.9231\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.7881e-08 - acc: 1.0000 - val_loss: 0.9534 - val_acc: 0.9231\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.4239e-08 - acc: 1.0000 - val_loss: 0.9124 - val_acc: 0.9231\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.2718e-09 - acc: 1.0000 - val_loss: 0.9093 - val_acc: 0.9231\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.6293e-09 - acc: 1.0000 - val_loss: 0.9157 - val_acc: 0.9231\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.6425e-09 - acc: 1.0000 - val_loss: 0.9195 - val_acc: 0.9231\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.6557e-09 - acc: 1.0000 - val_loss: 0.9134 - val_acc: 0.9231\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.6557e-09 - acc: 1.0000 - val_loss: 0.9155 - val_acc: 0.9231\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.3245e-09 - acc: 1.0000 - val_loss: 0.9245 - val_acc: 0.9231\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9196 - val_acc: 0.9231\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9284 - val_acc: 0.9231\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9302 - val_acc: 0.9231\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9412 - val_acc: 0.9231\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9535 - val_acc: 0.9231\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9684 - val_acc: 0.9231\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9540 - val_acc: 0.9231\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9453 - val_acc: 0.9231\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9438 - val_acc: 0.9231\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9561 - val_acc: 0.9231\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9639 - val_acc: 0.9231\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9434 - val_acc: 0.9231\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.8725 - val_acc: 0.9231\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1757 - acc: 0.9806 - val_loss: 7.2878 - val_acc: 0.4872\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6087 - acc: 0.9528 - val_loss: 1.0728 - val_acc: 0.8974\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.9914e-05 - acc: 1.0000 - val_loss: 1.0540 - val_acc: 0.8974\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.0888e-05 - acc: 1.0000 - val_loss: 1.0539 - val_acc: 0.8974\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8.3932e-06 - acc: 1.0000 - val_loss: 1.0526 - val_acc: 0.8974\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 6.5403e-06 - acc: 1.0000 - val_loss: 1.0520 - val_acc: 0.8974\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.7435e-06 - acc: 1.0000 - val_loss: 1.0510 - val_acc: 0.8974\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4818e-06 - acc: 1.0000 - val_loss: 1.0509 - val_acc: 0.8974\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.6731e-06 - acc: 1.0000 - val_loss: 1.0516 - val_acc: 0.8974\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.7022e-06 - acc: 1.0000 - val_loss: 1.0520 - val_acc: 0.8974\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.1751e-06 - acc: 1.0000 - val_loss: 1.0521 - val_acc: 0.8974\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.0396e-07 - acc: 1.0000 - val_loss: 1.0546 - val_acc: 0.8974\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.7484e-07 - acc: 1.0000 - val_loss: 1.0537 - val_acc: 0.8974\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.8378e-07 - acc: 1.0000 - val_loss: 1.0522 - val_acc: 0.8974\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.0497e-07 - acc: 1.0000 - val_loss: 1.0546 - val_acc: 0.8974\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.5762e-07 - acc: 1.0000 - val_loss: 1.0536 - val_acc: 0.8974\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.2484e-07 - acc: 1.0000 - val_loss: 1.0519 - val_acc: 0.8974\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.8214e-08 - acc: 1.0000 - val_loss: 1.0502 - val_acc: 0.8974\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.2717e-08 - acc: 1.0000 - val_loss: 1.0470 - val_acc: 0.8974\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.9802e-08 - acc: 1.0000 - val_loss: 1.0435 - val_acc: 0.8974\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.1524e-08 - acc: 1.0000 - val_loss: 1.0246 - val_acc: 0.8974\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.0596e-08 - acc: 1.0000 - val_loss: 1.0220 - val_acc: 0.8974\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.2784e-09 - acc: 1.0000 - val_loss: 1.0077 - val_acc: 0.8974\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.6293e-09 - acc: 1.0000 - val_loss: 1.0041 - val_acc: 0.8974\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4.6359e-09 - acc: 1.0000 - val_loss: 1.0016 - val_acc: 0.8974\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.9802e-09 - acc: 1.0000 - val_loss: 0.9975 - val_acc: 0.8974\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.3180e-09 - acc: 1.0000 - val_loss: 0.9889 - val_acc: 0.8974\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.3180e-09 - acc: 1.0000 - val_loss: 0.9830 - val_acc: 0.8974\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.3245e-09 - acc: 1.0000 - val_loss: 0.9778 - val_acc: 0.9231\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 0.9625 - val_acc: 0.9231\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9562 - val_acc: 0.9231\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9551 - val_acc: 0.9231\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9705 - val_acc: 0.9231\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9756 - val_acc: 0.9231\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9806 - val_acc: 0.9231\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9801 - val_acc: 0.9231\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9847 - val_acc: 0.9231\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9837 - val_acc: 0.9231\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9900 - val_acc: 0.9231\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9855 - val_acc: 0.9231\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9816 - val_acc: 0.9231\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9726 - val_acc: 0.9231\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9726 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9799 - val_acc: 0.9487\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9823 - val_acc: 0.9231\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9820 - val_acc: 0.9231\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9958 - val_acc: 0.9231\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 0.9485 - val_acc: 0.9487\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9396 - val_acc: 0.9487\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9046 - val_acc: 0.9487\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9213 - val_acc: 0.9487\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9019 - val_acc: 0.9487\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 0.8847 - val_acc: 0.9487\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8773 - val_acc: 0.9487\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8718 - val_acc: 0.9487\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8632 - val_acc: 0.9487\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7968 - acc: 0.9306 - val_loss: 1.1422 - val_acc: 0.9487\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0096 - acc: 0.9972 - val_loss: 1.0302 - val_acc: 0.8718\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.5786e-06 - acc: 1.0000 - val_loss: 1.1053 - val_acc: 0.8974\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.2036e-06 - acc: 1.0000 - val_loss: 1.1089 - val_acc: 0.8974\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.0606e-06 - acc: 1.0000 - val_loss: 1.1136 - val_acc: 0.8974\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9.2847e-07 - acc: 1.0000 - val_loss: 1.1454 - val_acc: 0.8974\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8.1258e-07 - acc: 1.0000 - val_loss: 1.1516 - val_acc: 0.8974\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7.1358e-07 - acc: 1.0000 - val_loss: 1.1583 - val_acc: 0.8974\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.2219e-07 - acc: 1.0000 - val_loss: 1.1648 - val_acc: 0.8974\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5.3212e-07 - acc: 1.0000 - val_loss: 1.1651 - val_acc: 0.8974\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.4173e-07 - acc: 1.0000 - val_loss: 1.1636 - val_acc: 0.8974\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.5563e-07 - acc: 1.0000 - val_loss: 1.1754 - val_acc: 0.8974\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.8411e-07 - acc: 1.0000 - val_loss: 1.1782 - val_acc: 0.8974\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.0232e-07 - acc: 1.0000 - val_loss: 1.1703 - val_acc: 0.8974\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.5365e-07 - acc: 1.0000 - val_loss: 1.1849 - val_acc: 0.8974\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1731 - val_acc: 0.8974\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.9738e-08 - acc: 1.0000 - val_loss: 1.1636 - val_acc: 0.8974\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.6889e-08 - acc: 1.0000 - val_loss: 1.1990 - val_acc: 0.8974\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5.1657e-08 - acc: 1.0000 - val_loss: 1.1774 - val_acc: 0.8974\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.5763e-08 - acc: 1.0000 - val_loss: 1.1636 - val_acc: 0.8974\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.7815e-08 - acc: 1.0000 - val_loss: 1.1535 - val_acc: 0.8974\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.0862e-08 - acc: 1.0000 - val_loss: 1.1456 - val_acc: 0.8974\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.8544e-08 - acc: 1.0000 - val_loss: 1.1190 - val_acc: 0.8974\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.1590e-08 - acc: 1.0000 - val_loss: 1.1240 - val_acc: 0.8974\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9.2718e-09 - acc: 1.0000 - val_loss: 1.1208 - val_acc: 0.8974\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.6425e-09 - acc: 1.0000 - val_loss: 1.1100 - val_acc: 0.8974\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.6491e-09 - acc: 1.0000 - val_loss: 1.1005 - val_acc: 0.8974\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.6557e-09 - acc: 1.0000 - val_loss: 1.1010 - val_acc: 0.8974\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 1.0919 - val_acc: 0.8974\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 1.0863 - val_acc: 0.8974\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.0865 - val_acc: 0.8974\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.1061 - val_acc: 0.8974\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0997 - val_acc: 0.8974\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0944 - val_acc: 0.8974\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0943 - val_acc: 0.8974\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1033 - val_acc: 0.8974\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.0873 - val_acc: 0.8974\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0791 - val_acc: 0.8974\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 0.9973 - val_acc: 0.9231\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 1.0389 - val_acc: 0.9231\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.0026 - val_acc: 0.9231\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 0.8560 - val_acc: 0.9487\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8521 - val_acc: 0.9487\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.8584 - val_acc: 0.9487\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8573 - val_acc: 0.9487\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8518 - val_acc: 0.9487\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 0.8193 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.2613 - acc: 0.9083 - val_loss: 1.0633 - val_acc: 0.9231\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.0326e-04 - acc: 1.0000 - val_loss: 1.0585 - val_acc: 0.9231\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5.9302e-05 - acc: 1.0000 - val_loss: 1.0486 - val_acc: 0.9231\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.9970e-05 - acc: 1.0000 - val_loss: 1.0383 - val_acc: 0.9231\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.7982e-05 - acc: 1.0000 - val_loss: 1.0274 - val_acc: 0.9231\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.0077e-05 - acc: 1.0000 - val_loss: 1.0180 - val_acc: 0.9231\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.4517e-05 - acc: 1.0000 - val_loss: 1.0081 - val_acc: 0.9231\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.0829e-05 - acc: 1.0000 - val_loss: 0.9978 - val_acc: 0.9231\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.8844e-06 - acc: 1.0000 - val_loss: 0.9865 - val_acc: 0.9231\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 5.7641e-06 - acc: 1.0000 - val_loss: 0.9770 - val_acc: 0.9231\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.3698e-06 - acc: 1.0000 - val_loss: 0.9653 - val_acc: 0.9231\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.0412e-06 - acc: 1.0000 - val_loss: 0.9357 - val_acc: 0.9231\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.9927e-06 - acc: 1.0000 - val_loss: 0.9339 - val_acc: 0.9231\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.3662e-06 - acc: 1.0000 - val_loss: 0.9280 - val_acc: 0.9231\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9.8477e-07 - acc: 1.0000 - val_loss: 0.9082 - val_acc: 0.9231\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.6127e-07 - acc: 1.0000 - val_loss: 0.9181 - val_acc: 0.9231\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 4.3610e-07 - acc: 1.0000 - val_loss: 0.9058 - val_acc: 0.9231\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.0233e-07 - acc: 1.0000 - val_loss: 0.9245 - val_acc: 0.9231\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.9073e-07 - acc: 1.0000 - val_loss: 0.9066 - val_acc: 0.9231\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.2616e-07 - acc: 1.0000 - val_loss: 0.8904 - val_acc: 0.9231\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.2784e-08 - acc: 1.0000 - val_loss: 0.8903 - val_acc: 0.9231\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.6293e-08 - acc: 1.0000 - val_loss: 0.8716 - val_acc: 0.9231\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.0068e-08 - acc: 1.0000 - val_loss: 0.8504 - val_acc: 0.9231\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.5498e-08 - acc: 1.0000 - val_loss: 0.8456 - val_acc: 0.9231\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.7219e-08 - acc: 1.0000 - val_loss: 0.8348 - val_acc: 0.9231\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.1921e-08 - acc: 1.0000 - val_loss: 0.8560 - val_acc: 0.9231\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7.9473e-09 - acc: 1.0000 - val_loss: 0.8235 - val_acc: 0.9231\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4.3048e-09 - acc: 1.0000 - val_loss: 0.8327 - val_acc: 0.9231\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.9802e-09 - acc: 1.0000 - val_loss: 0.8029 - val_acc: 0.9231\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.6557e-09 - acc: 1.0000 - val_loss: 0.8178 - val_acc: 0.9231\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 0.8143 - val_acc: 0.9231\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8046 - val_acc: 0.9231\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.8001 - val_acc: 0.9231\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7966 - val_acc: 0.9231\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7982 - val_acc: 0.9231\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7924 - val_acc: 0.9231\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7891 - val_acc: 0.9231\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7857 - val_acc: 0.9231\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7823 - val_acc: 0.9231\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7806 - val_acc: 0.9231\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7806 - val_acc: 0.8974\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7800 - val_acc: 0.8974\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7824 - val_acc: 0.8974\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7891 - val_acc: 0.8974\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7943 - val_acc: 0.8974\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7971 - val_acc: 0.9231\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8000 - val_acc: 0.9231\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8032 - val_acc: 0.9231\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8064 - val_acc: 0.9231\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8095 - val_acc: 0.9231\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8115 - val_acc: 0.9231\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8106 - val_acc: 0.9231\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8140 - val_acc: 0.9231\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8161 - val_acc: 0.9231\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8184 - val_acc: 0.9231\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8242 - val_acc: 0.9231\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8250 - val_acc: 0.9231\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8235 - val_acc: 0.9231\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8239 - val_acc: 0.9231\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8231 - val_acc: 0.9231\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8165 - val_acc: 0.9231\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8170 - val_acc: 0.9231\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8178 - val_acc: 0.9231\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8175 - val_acc: 0.9231\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8169 - val_acc: 0.9487\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8143 - val_acc: 0.9487\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8121 - val_acc: 0.9487\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8157 - val_acc: 0.9231\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8126 - val_acc: 0.9487\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.7536 - val_acc: 0.9487\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-09 - acc: 1.0000 - val_loss: 0.6607 - val_acc: 0.9487\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.8504 - acc: 0.9389 - val_loss: 1.2006 - val_acc: 0.8974\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.4028e-04 - acc: 1.0000 - val_loss: 1.2468 - val_acc: 0.8974\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.0425e-06 - acc: 1.0000 - val_loss: 1.2454 - val_acc: 0.8974\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.7574e-06 - acc: 1.0000 - val_loss: 1.2442 - val_acc: 0.8974\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.6555e-06 - acc: 1.0000 - val_loss: 1.2430 - val_acc: 0.8974\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.5485e-06 - acc: 1.0000 - val_loss: 1.2419 - val_acc: 0.8974\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.4145e-06 - acc: 1.0000 - val_loss: 1.2409 - val_acc: 0.8974\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.2579e-06 - acc: 1.0000 - val_loss: 1.2404 - val_acc: 0.8974\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.1056e-06 - acc: 1.0000 - val_loss: 1.2393 - val_acc: 0.8974\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9.1421e-07 - acc: 1.0000 - val_loss: 1.2377 - val_acc: 0.8974\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.6058e-07 - acc: 1.0000 - val_loss: 1.2358 - val_acc: 0.8974\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 6.3807e-07 - acc: 1.0000 - val_loss: 1.2594 - val_acc: 0.8974\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.2506e-06 - acc: 1.0000 - val_loss: 1.2651 - val_acc: 0.8974\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.9173e-07 - acc: 1.0000 - val_loss: 1.2531 - val_acc: 0.8974\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.8444e-07 - acc: 1.0000 - val_loss: 1.2433 - val_acc: 0.8974\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.0327e-07 - acc: 1.0000 - val_loss: 1.1873 - val_acc: 0.8974\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.0199e-07 - acc: 1.0000 - val_loss: 1.1777 - val_acc: 0.8974\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7.5830e-08 - acc: 1.0000 - val_loss: 1.1705 - val_acc: 0.8974\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5.7949e-08 - acc: 1.0000 - val_loss: 1.1658 - val_acc: 0.8974\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4.3710e-08 - acc: 1.0000 - val_loss: 1.1632 - val_acc: 0.8974\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3445e-08 - acc: 1.0000 - val_loss: 1.1564 - val_acc: 0.8974\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.4504e-08 - acc: 1.0000 - val_loss: 1.1505 - val_acc: 0.9231\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.8544e-08 - acc: 1.0000 - val_loss: 1.1480 - val_acc: 0.9231\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.3245e-08 - acc: 1.0000 - val_loss: 1.1412 - val_acc: 0.9231\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.9407e-09 - acc: 1.0000 - val_loss: 1.1283 - val_acc: 0.9231\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.6227e-09 - acc: 1.0000 - val_loss: 1.1219 - val_acc: 0.9231\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.6359e-09 - acc: 1.0000 - val_loss: 1.1283 - val_acc: 0.9231\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.9736e-09 - acc: 1.0000 - val_loss: 1.0895 - val_acc: 0.9231\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.9868e-09 - acc: 1.0000 - val_loss: 1.0750 - val_acc: 0.9231\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 1.0683 - val_acc: 0.9231\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3245e-09 - acc: 1.0000 - val_loss: 1.0608 - val_acc: 0.9231\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 1.0531 - val_acc: 0.9231\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0464 - val_acc: 0.9231\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0447 - val_acc: 0.9231\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0411 - val_acc: 0.9231\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0276 - val_acc: 0.9231\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9594 - val_acc: 0.9231\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 0.9866 - val_acc: 0.9231\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9676 - val_acc: 0.9231\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9305 - val_acc: 0.9231\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9128 - val_acc: 0.9231\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8783 - val_acc: 0.9231\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.8146 - val_acc: 0.9231\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.9199 - val_acc: 0.8974\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8964 - val_acc: 0.8974\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8815 - val_acc: 0.8974\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8673 - val_acc: 0.8974\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8574 - val_acc: 0.8974\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8287 - val_acc: 0.8974\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7851 - val_acc: 0.9231\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3143 - acc: 0.9889 - val_loss: 10.2476 - val_acc: 0.4615\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3657 - acc: 0.9556 - val_loss: 1.6899 - val_acc: 0.8974\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.1070e-06 - acc: 1.0000 - val_loss: 1.6818 - val_acc: 0.8974\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4.6159e-06 - acc: 1.0000 - val_loss: 1.6725 - val_acc: 0.8974\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4.0746e-06 - acc: 1.0000 - val_loss: 1.6620 - val_acc: 0.8974\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.5276e-06 - acc: 1.0000 - val_loss: 1.6456 - val_acc: 0.8974\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.8771e-06 - acc: 1.0000 - val_loss: 1.6024 - val_acc: 0.9231\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.2509e-06 - acc: 1.0000 - val_loss: 1.5891 - val_acc: 0.9231\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.7137e-06 - acc: 1.0000 - val_loss: 1.5727 - val_acc: 0.9231\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.1797e-06 - acc: 1.0000 - val_loss: 1.5559 - val_acc: 0.9231\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.4996e-07 - acc: 1.0000 - val_loss: 1.5388 - val_acc: 0.9231\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.1820e-07 - acc: 1.0000 - val_loss: 1.5163 - val_acc: 0.9231\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.0861e-07 - acc: 1.0000 - val_loss: 1.4943 - val_acc: 0.9231\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.8146e-07 - acc: 1.0000 - val_loss: 1.4704 - val_acc: 0.9231\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.9802e-07 - acc: 1.0000 - val_loss: 1.4438 - val_acc: 0.9231\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.3510e-07 - acc: 1.0000 - val_loss: 1.4239 - val_acc: 0.9231\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.8347e-08 - acc: 1.0000 - val_loss: 1.3941 - val_acc: 0.9231\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.3247e-08 - acc: 1.0000 - val_loss: 1.3644 - val_acc: 0.9231\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4.5035e-08 - acc: 1.0000 - val_loss: 1.3335 - val_acc: 0.9231\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.0796e-08 - acc: 1.0000 - val_loss: 1.3384 - val_acc: 0.9231\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.1524e-08 - acc: 1.0000 - val_loss: 1.3020 - val_acc: 0.9231\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.6557e-08 - acc: 1.0000 - val_loss: 1.2623 - val_acc: 0.9231\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0928e-08 - acc: 1.0000 - val_loss: 1.2074 - val_acc: 0.9231\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4.9671e-09 - acc: 1.0000 - val_loss: 1.1984 - val_acc: 0.9231\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.9736e-09 - acc: 1.0000 - val_loss: 1.1881 - val_acc: 0.9231\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-09 - acc: 1.0000 - val_loss: 1.1775 - val_acc: 0.9231\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.6491e-09 - acc: 1.0000 - val_loss: 1.1663 - val_acc: 0.9231\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.6491e-09 - acc: 1.0000 - val_loss: 1.1531 - val_acc: 0.9231\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 1.1417 - val_acc: 0.9231\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1344 - val_acc: 0.9231\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1269 - val_acc: 0.9231\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1164 - val_acc: 0.9231\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.1041 - val_acc: 0.9231\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0907 - val_acc: 0.9231\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0758 - val_acc: 0.9231\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0579 - val_acc: 0.9231\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0411 - val_acc: 0.9231\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0269 - val_acc: 0.9231\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0003 - val_acc: 0.9231\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9801 - val_acc: 0.9231\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9641 - val_acc: 0.9487\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9521 - val_acc: 0.9487\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9407 - val_acc: 0.9487\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9304 - val_acc: 0.9487\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9200 - val_acc: 0.9487\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9122 - val_acc: 0.9487\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9005 - val_acc: 0.9487\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8911 - val_acc: 0.9744\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8818 - val_acc: 0.9744\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8701 - val_acc: 0.9231\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8454 - val_acc: 0.9487\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.8341 - val_acc: 0.9231\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9730 - acc: 0.9528 - val_loss: 1.9145 - val_acc: 0.8462\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0096 - acc: 0.9972 - val_loss: 0.8724 - val_acc: 0.9487\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.9084e-04 - acc: 1.0000 - val_loss: 1.0252 - val_acc: 0.9231\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.4988e-06 - acc: 1.0000 - val_loss: 1.0270 - val_acc: 0.9231\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.1995e-06 - acc: 1.0000 - val_loss: 1.0285 - val_acc: 0.9231\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.4165e-07 - acc: 1.0000 - val_loss: 1.0296 - val_acc: 0.9231\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.3209e-07 - acc: 1.0000 - val_loss: 1.0300 - val_acc: 0.9231\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.7284e-07 - acc: 1.0000 - val_loss: 1.0320 - val_acc: 0.9231\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.2517e-07 - acc: 1.0000 - val_loss: 1.0329 - val_acc: 0.9231\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.2583e-07 - acc: 1.0000 - val_loss: 1.0343 - val_acc: 0.9231\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.5067e-07 - acc: 1.0000 - val_loss: 1.0353 - val_acc: 0.9231\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.9106e-07 - acc: 1.0000 - val_loss: 1.0364 - val_acc: 0.9231\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.2186e-07 - acc: 1.0000 - val_loss: 1.0375 - val_acc: 0.9231\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.4042e-08 - acc: 1.0000 - val_loss: 1.0389 - val_acc: 0.9231\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 8.5764e-08 - acc: 1.0000 - val_loss: 1.0394 - val_acc: 0.9231\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 8.9738e-08 - acc: 1.0000 - val_loss: 1.0402 - val_acc: 0.9231\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.7418e-08 - acc: 1.0000 - val_loss: 1.0412 - val_acc: 0.9231\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.6822e-08 - acc: 1.0000 - val_loss: 1.0425 - val_acc: 0.9231\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.9206e-08 - acc: 1.0000 - val_loss: 1.0603 - val_acc: 0.9487\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9.9341e-09 - acc: 1.0000 - val_loss: 1.0593 - val_acc: 0.9487\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7.6161e-09 - acc: 1.0000 - val_loss: 1.0582 - val_acc: 0.9487\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.6293e-09 - acc: 1.0000 - val_loss: 1.0578 - val_acc: 0.9487\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.6359e-09 - acc: 1.0000 - val_loss: 1.0570 - val_acc: 0.9487\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 3.3114e-09 - acc: 1.0000 - val_loss: 1.0568 - val_acc: 0.9487\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.3180e-09 - acc: 1.0000 - val_loss: 1.0559 - val_acc: 0.9487\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3245e-09 - acc: 1.0000 - val_loss: 1.0562 - val_acc: 0.9487\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.9341e-10 - acc: 1.0000 - val_loss: 1.0532 - val_acc: 0.9487\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0551 - val_acc: 0.9487\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0570 - val_acc: 0.9487\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0577 - val_acc: 0.9487\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0571 - val_acc: 0.9487\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0747 - val_acc: 0.9231\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0605 - val_acc: 0.8974\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0474 - val_acc: 0.8974\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0334 - val_acc: 0.8974\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0184 - val_acc: 0.8974\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0111 - val_acc: 0.9231\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0028 - val_acc: 0.9231\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9961 - val_acc: 0.9231\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9883 - val_acc: 0.9231\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9921 - val_acc: 0.9231\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.9893 - val_acc: 0.9231\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.3245e-09 - acc: 1.0000 - val_loss: 1.2806 - val_acc: 0.8974\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.1034 - acc: 0.9528 - val_loss: 0.5453 - val_acc: 0.9231\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.5733e-06 - acc: 1.0000 - val_loss: 0.4923 - val_acc: 0.9487\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.3409e-06 - acc: 1.0000 - val_loss: 0.5110 - val_acc: 0.9487\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.1893e-06 - acc: 1.0000 - val_loss: 0.5175 - val_acc: 0.9487\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0535e-06 - acc: 1.0000 - val_loss: 0.5250 - val_acc: 0.9487\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 9.2409e-07 - acc: 1.0000 - val_loss: 0.5346 - val_acc: 0.9487\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7.6551e-07 - acc: 1.0000 - val_loss: 0.5457 - val_acc: 0.9487\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.2580e-07 - acc: 1.0000 - val_loss: 0.5573 - val_acc: 0.9487\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 5.0164e-07 - acc: 1.0000 - val_loss: 0.5697 - val_acc: 0.9487\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.6291e-07 - acc: 1.0000 - val_loss: 0.5848 - val_acc: 0.9487\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.6523e-07 - acc: 1.0000 - val_loss: 0.6010 - val_acc: 0.9487\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.4174e-08 - acc: 1.0000 - val_loss: 0.6177 - val_acc: 0.9487\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.5896e-08 - acc: 1.0000 - val_loss: 0.6346 - val_acc: 0.9487\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.7949e-08 - acc: 1.0000 - val_loss: 0.6023 - val_acc: 0.9487\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.0002e-08 - acc: 1.0000 - val_loss: 0.6447 - val_acc: 0.9487\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.2385e-08 - acc: 1.0000 - val_loss: 0.6648 - val_acc: 0.9487\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3445e-08 - acc: 1.0000 - val_loss: 0.6849 - val_acc: 0.9487\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.4173e-08 - acc: 1.0000 - val_loss: 0.6709 - val_acc: 0.9487\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.8213e-08 - acc: 1.0000 - val_loss: 0.6991 - val_acc: 0.9487\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.3245e-08 - acc: 1.0000 - val_loss: 0.7240 - val_acc: 0.9487\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.9341e-09 - acc: 1.0000 - val_loss: 0.7388 - val_acc: 0.9487\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.9539e-09 - acc: 1.0000 - val_loss: 0.7625 - val_acc: 0.9487\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4.9671e-09 - acc: 1.0000 - val_loss: 0.7031 - val_acc: 0.9487\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.3114e-09 - acc: 1.0000 - val_loss: 0.7286 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.3180e-09 - acc: 1.0000 - val_loss: 0.7958 - val_acc: 0.9487\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.6557e-09 - acc: 1.0000 - val_loss: 0.7135 - val_acc: 0.9487\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.3245e-09 - acc: 1.0000 - val_loss: 0.7177 - val_acc: 0.9487\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 0.7195 - val_acc: 0.9487\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.6227e-10 - acc: 1.0000 - val_loss: 0.7313 - val_acc: 0.9487\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.7326 - val_acc: 0.9487\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7315 - val_acc: 0.9487\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7329 - val_acc: 0.9487\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7455 - val_acc: 0.9487\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7482 - val_acc: 0.9487\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.7595 - val_acc: 0.9487\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7627 - val_acc: 0.9231\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7660 - val_acc: 0.9231\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7702 - val_acc: 0.9231\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7749 - val_acc: 0.9231\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7783 - val_acc: 0.9231\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7810 - val_acc: 0.9231\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7820 - val_acc: 0.9487\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7803 - val_acc: 0.9487\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8025 - val_acc: 0.9231\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7717 - val_acc: 0.9487\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7757 - val_acc: 0.9487\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7774 - val_acc: 0.9487\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7903 - val_acc: 0.9487\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7967 - val_acc: 0.9487\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.7774 - val_acc: 0.9487\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8133 - val_acc: 0.9231\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.8087 - val_acc: 0.9231\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.7283 - val_acc: 0.9231\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.3114e-09 - acc: 1.0000 - val_loss: 0.6569 - val_acc: 0.9487\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.3114e-10 - acc: 1.0000 - val_loss: 0.6959 - val_acc: 0.9231\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 0.7090 - val_acc: 0.9231\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6555 - acc: 0.9472 - val_loss: 11.8923 - val_acc: 0.5128\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5378 - acc: 0.9528 - val_loss: 1.6099 - val_acc: 0.8718\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 8.5589e-04 - acc: 1.0000 - val_loss: 1.4108 - val_acc: 0.8974\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 7.0532e-05 - acc: 1.0000 - val_loss: 1.3945 - val_acc: 0.8974\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3655e-05 - acc: 1.0000 - val_loss: 1.3795 - val_acc: 0.8974\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.0275e-05 - acc: 1.0000 - val_loss: 1.3704 - val_acc: 0.8974\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.5002e-05 - acc: 1.0000 - val_loss: 1.3622 - val_acc: 0.8974\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.1450e-05 - acc: 1.0000 - val_loss: 1.3513 - val_acc: 0.8974\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.2859e-06 - acc: 1.0000 - val_loss: 1.3409 - val_acc: 0.9231\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6.1476e-06 - acc: 1.0000 - val_loss: 1.3305 - val_acc: 0.9231\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4.5904e-06 - acc: 1.0000 - val_loss: 1.3209 - val_acc: 0.9231\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3379e-06 - acc: 1.0000 - val_loss: 1.3109 - val_acc: 0.9231\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.4463e-06 - acc: 1.0000 - val_loss: 1.3007 - val_acc: 0.9231\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.7212e-06 - acc: 1.0000 - val_loss: 1.2914 - val_acc: 0.9231\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.2603e-06 - acc: 1.0000 - val_loss: 1.2796 - val_acc: 0.9231\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.7187e-07 - acc: 1.0000 - val_loss: 1.2702 - val_acc: 0.9231\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 5.7683e-07 - acc: 1.0000 - val_loss: 1.2610 - val_acc: 0.9231\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 4.0167e-07 - acc: 1.0000 - val_loss: 1.2563 - val_acc: 0.9231\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.5266e-07 - acc: 1.0000 - val_loss: 1.2467 - val_acc: 0.9231\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.7815e-07 - acc: 1.0000 - val_loss: 1.2376 - val_acc: 0.9231\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.2418e-07 - acc: 1.0000 - val_loss: 1.2292 - val_acc: 0.9231\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8.5433e-08 - acc: 1.0000 - val_loss: 1.2227 - val_acc: 0.8974\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5.7287e-08 - acc: 1.0000 - val_loss: 1.2219 - val_acc: 0.8974\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.7418e-08 - acc: 1.0000 - val_loss: 1.2149 - val_acc: 0.8974\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.7815e-08 - acc: 1.0000 - val_loss: 1.2068 - val_acc: 0.8974\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.9537e-08 - acc: 1.0000 - val_loss: 1.2354 - val_acc: 0.8974\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.5895e-08 - acc: 1.0000 - val_loss: 1.2051 - val_acc: 0.8974\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0596e-08 - acc: 1.0000 - val_loss: 1.1785 - val_acc: 0.8974\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7.2850e-09 - acc: 1.0000 - val_loss: 1.1718 - val_acc: 0.8974\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.9671e-09 - acc: 1.0000 - val_loss: 1.1618 - val_acc: 0.8974\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.3114e-09 - acc: 1.0000 - val_loss: 1.1426 - val_acc: 0.8974\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.6557e-09 - acc: 1.0000 - val_loss: 1.1986 - val_acc: 0.8718\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9.6030e-09 - acc: 1.0000 - val_loss: 1.0155 - val_acc: 0.9231\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.9539e-09 - acc: 1.0000 - val_loss: 1.2027 - val_acc: 0.8718\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.9671e-09 - acc: 1.0000 - val_loss: 1.0348 - val_acc: 0.9231\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0403 - val_acc: 0.9231\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0331 - val_acc: 0.9231\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0366 - val_acc: 0.9231\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0396 - val_acc: 0.9231\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0434 - val_acc: 0.9231\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0509 - val_acc: 0.9231\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0519 - val_acc: 0.9231\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0534 - val_acc: 0.9231\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 1.0000 - val_loss: 1.0568 - val_acc: 0.9231\n"
     ]
    }
   ],
   "source": [
    "s=0.0\n",
    "for i in range(1, 50):\n",
    "    model.fit(x_train, y_train, batch_size=50, epochs=30, validation_data=(x_val, y_val))\n",
    "    scores=model.evaluate(x_val, y_val, verbose=0)\n",
    "    s=s+(scores[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "allied-bouquet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('acc', 92.30769276618958)\n"
     ]
    }
   ],
   "source": [
    "scores=model.evaluate(x_val, y_val, verbose=0)\n",
    "print((model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-sixth",
   "metadata": {},
   "source": [
    "<p> The accuracy of the model varies from 85% - 95%. We can improve the accuracy by fluctuating the hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "trained-healing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=kindly undo the changes, Predicted=1 \n",
      "X=Can you please undo the last paragraph, \n",
      "Predicted=1 \n",
      "X=Make bold this, \n",
      "Predicted=2 \n",
      "X=Would you be kind enough to bold the last word?, Predicted=2 \n",
      "X=Please remove bold from the last paragraph, Predicted=3 \n",
      "X=Kindly unbold the selected text, Predicted=3 \n",
      "X=Kindly insert comment here, Predicted=19 \n",
      "X=Can you please put a comment here, Predicted=15 \n",
      "X=Can you please centre align this text, Predicted=14 \n",
      "X=Can you please position this text in the middle, Predicted=14\n"
     ]
    }
   ],
   "source": [
    "Xnew=[\"kindly undo the changes\",\"Can you please undo the last paragraph\",\"Make bold this\",\"Would you be kind enough to bold the last word?\",\"Please remove bold from the last paragraph\",\"Kindly unbold the selected text\",\"Kindly insert comment here\",\"Can you please put a comment here\",\"Can you please centre align this text\",\"Can you please position this text in the middle\"]\n",
    "sequences_new=tokenizer.texts_to_sequences(Xnew)\n",
    "data=pad_sequences(sequences_new, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "yprob=model.predict(data)\n",
    "yclasses=yprob.argmax(axis=1)\n",
    "print(\"X=%s, Predicted=%s \\nX=%s, \\nPredicted=%s \\nX=%s, \\nPredicted=%s \\nX=%s, Predicted=%s \\nX=%s, Predicted=%s \\nX=%s, Predicted=%s \\nX=%s, Predicted=%s \\nX=%s, Predicted=%s \\nX=%s, Predicted=%s \\nX=%s, Predicted=%s\" % (Xnew[0], yclasses[0],Xnew[1],yclasses[1],Xnew[2],yclasses[2],Xnew[3],yclasses[3],Xnew[4],yclasses[4],Xnew[5],yclasses[5],Xnew[6],yclasses[6],Xnew[7],yclasses[7],Xnew[8],yclasses[8],Xnew[9],yclasses[9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-patrol",
   "metadata": {},
   "source": [
    "<p> CNN worked well when passed through the dataset.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-feelings",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "premier-profession",
   "metadata": {},
   "source": [
    "## Intent Classification using Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "olive-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, BatchNormalization, Dropout, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-adams",
   "metadata": {},
   "source": [
    "<p> ATIS is a most common dataset used for intent classification. The dataset contains large number of messages and their intents.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "accepted-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(r'D:\\Surrey\\Semester\\Semester 2\\NLP\\atis_intents_train.csv')\n",
    "train.columns=['intent', 'snippet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "small-directory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>what flights are available from pittsburgh to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atis_flight_time</td>\n",
       "      <td>what is the arrival time in san francisco for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atis_airfare</td>\n",
       "      <td>cheapest airfare from tacoma to orlando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atis_airfare</td>\n",
       "      <td>round trip fares from pittsburgh to philadelp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>i need a flight tomorrow from columbus to min...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             intent                                            snippet\n",
       "0       atis_flight   what flights are available from pittsburgh to...\n",
       "1  atis_flight_time   what is the arrival time in san francisco for...\n",
       "2      atis_airfare            cheapest airfare from tacoma to orlando\n",
       "3      atis_airfare   round trip fares from pittsburgh to philadelp...\n",
       "4       atis_flight   i need a flight tomorrow from columbus to min..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "classical-angel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(atis_flight            3665\n",
       " atis_airfare            423\n",
       " atis_ground_service     255\n",
       " atis_airline            157\n",
       " atis_abbreviation       147\n",
       " atis_aircraft            81\n",
       " atis_flight_time         54\n",
       " atis_quantity            51\n",
       " Name: intent, dtype: int64,\n",
       " atis_flight            0.758328\n",
       " atis_airfare           0.087523\n",
       " atis_ground_service    0.052762\n",
       " atis_airline           0.032485\n",
       " atis_abbreviation      0.030416\n",
       " atis_aircraft          0.016760\n",
       " atis_flight_time       0.011173\n",
       " atis_quantity          0.010552\n",
       " Name: intent, dtype: float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.intent.value_counts(), train.intent.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "worldwide-bailey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(atis_flight            3665\n",
       " atis_airfare            423\n",
       " atis_ground_service     255\n",
       " atis_airline            157\n",
       " atis_abbreviation       147\n",
       " atis_aircraft            81\n",
       " atis_flight_time         54\n",
       " atis_quantity            51\n",
       " Name: intent, dtype: int64,\n",
       " atis_flight            0.758328\n",
       " atis_airfare           0.087523\n",
       " atis_ground_service    0.052762\n",
       " atis_airline           0.032485\n",
       " atis_abbreviation      0.030416\n",
       " atis_aircraft          0.016760\n",
       " atis_flight_time       0.011173\n",
       " atis_quantity          0.010552\n",
       " Name: intent, dtype: float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.intent.value_counts(), train.intent.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "terminal-certification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atis_airfare</td>\n",
       "      <td>on april first i need a ticket from tacoma to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>on april first i need a flight going from pho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>i would like a flight traveling one way from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>i would like a flight from orlando to salt la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>i need a flight from toronto to newark one wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         intent                                            snippet\n",
       "0  atis_airfare   on april first i need a ticket from tacoma to...\n",
       "1   atis_flight   on april first i need a flight going from pho...\n",
       "2   atis_flight   i would like a flight traveling one way from ...\n",
       "3   atis_flight   i would like a flight from orlando to salt la...\n",
       "4   atis_flight   i need a flight from toronto to newark one wa..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_csv(r'D:\\Surrey\\Semester\\Semester 2\\NLP\\atis_intents_test.csv')\n",
    "test.columns=['intent', 'snippet']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "surface-contractor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(atis_flight            631\n",
       " atis_airfare            48\n",
       " atis_airline            38\n",
       " atis_ground_service     36\n",
       " atis_abbreviation       33\n",
       " atis_aircraft            9\n",
       " atis_quantity            3\n",
       " atis_flight_time         1\n",
       " Name: intent, dtype: int64,\n",
       " atis_flight            0.789737\n",
       " atis_airfare           0.060075\n",
       " atis_airline           0.047559\n",
       " atis_ground_service    0.045056\n",
       " atis_abbreviation      0.041302\n",
       " atis_aircraft          0.011264\n",
       " atis_quantity          0.003755\n",
       " atis_flight_time       0.001252\n",
       " Name: intent, dtype: float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.intent.value_counts(), test.intent.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "impressive-crime",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4833, 4833, 799, 799)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train.snippet.values\n",
    "train_labels = train.intent.values\n",
    "test_data = test.snippet.values\n",
    "test_labels = test.intent.values\n",
    "\n",
    "len(train_data), len(train_labels), len(test_data), len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aquatic-appeal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " okay i need to get a flight from houston to seattle\n",
      "atis_flight\n"
     ]
    }
   ],
   "source": [
    "print(train_data[123])\n",
    "print(train_labels[123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "educated-accused",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4833, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atis_abbreviation</th>\n",
       "      <th>atis_aircraft</th>\n",
       "      <th>atis_airfare</th>\n",
       "      <th>atis_airline</th>\n",
       "      <th>atis_flight</th>\n",
       "      <th>atis_flight_time</th>\n",
       "      <th>atis_ground_service</th>\n",
       "      <th>atis_quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   atis_abbreviation  atis_aircraft  atis_airfare  atis_airline  atis_flight  \\\n",
       "0                  0              0             0             0            1   \n",
       "1                  0              0             0             0            0   \n",
       "2                  0              0             1             0            0   \n",
       "3                  0              0             1             0            0   \n",
       "4                  0              0             0             0            1   \n",
       "\n",
       "   atis_flight_time  atis_ground_service  atis_quantity  \n",
       "0                 0                    0              0  \n",
       "1                 1                    0              0  \n",
       "2                 0                    0              0  \n",
       "3                 0                    0              0  \n",
       "4                 0                    0              0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.get_dummies(train_labels)\n",
    "print(y_train.shape)\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "synthetic-porter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(799, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atis_abbreviation</th>\n",
       "      <th>atis_aircraft</th>\n",
       "      <th>atis_airfare</th>\n",
       "      <th>atis_airline</th>\n",
       "      <th>atis_flight</th>\n",
       "      <th>atis_flight_time</th>\n",
       "      <th>atis_ground_service</th>\n",
       "      <th>atis_quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   atis_abbreviation  atis_aircraft  atis_airfare  atis_airline  atis_flight  \\\n",
       "0                  0              0             1             0            0   \n",
       "1                  0              0             0             0            1   \n",
       "2                  0              0             0             0            1   \n",
       "3                  0              0             0             0            1   \n",
       "4                  0              0             0             0            1   \n",
       "\n",
       "   atis_flight_time  atis_ground_service  atis_quantity  \n",
       "0                 0                    0              0  \n",
       "1                 0                    0              0  \n",
       "2                 0                    0              0  \n",
       "3                 0                    0              0  \n",
       "4                 0                    0              0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = pd.get_dummies(test_labels)\n",
    "print(y_test.shape)\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-genealogy",
   "metadata": {},
   "source": [
    "<p> Universal Sentence Encoder is developer tool from Google which is used as a Python Library for Intent Classifcation. </p>\n",
    "\n",
    "<p> Initially this link will take time to load depending on your system. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "yellow-break",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "module_url = 'https://tfhub.dev/google/universal-sentence-encoder-large/4'\n",
    "embed = hub.KerasLayer(module_url, trainable=True, name='USE_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "french-conditioning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE_embedding (KerasLayer)  {'outputs': (None, 512)}  147354880 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 4104      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 147,358,984\n",
      "Trainable params: 147,358,984\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(embed):\n",
    "    \n",
    "    model = Sequential([\n",
    "        Input(shape=[], dtype=tf.string),\n",
    "        embed,\n",
    "        Dense(8, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model(embed)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "empty-blair",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_29:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_29:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_29:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_29:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_17:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_18:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_19:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_20:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_21:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_22:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_23:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_24:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_25:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_26:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_27:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_28:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_29:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 300s 2s/step - loss: 1.6702 - accuracy: 0.7142 - val_loss: 1.3657 - val_accuracy: 0.7497\n",
      "Epoch 2/10\n",
      "121/121 [==============================] - 205s 2s/step - loss: 1.2536 - accuracy: 0.7770 - val_loss: 1.1902 - val_accuracy: 0.8108\n",
      "Epoch 3/10\n",
      "121/121 [==============================] - 202s 2s/step - loss: 1.1249 - accuracy: 0.8531 - val_loss: 1.0699 - val_accuracy: 0.9080\n",
      "Epoch 4/10\n",
      "121/121 [==============================] - 194s 2s/step - loss: 1.0263 - accuracy: 0.9296 - val_loss: 0.9832 - val_accuracy: 0.9731\n",
      "Epoch 5/10\n",
      "121/121 [==============================] - 191s 2s/step - loss: 0.9560 - accuracy: 0.9713 - val_loss: 0.9228 - val_accuracy: 0.9835\n",
      "Epoch 6/10\n",
      "121/121 [==============================] - 194s 2s/step - loss: 0.9035 - accuracy: 0.9801 - val_loss: 0.8787 - val_accuracy: 0.9845\n",
      "Epoch 7/10\n",
      "121/121 [==============================] - 195s 2s/step - loss: 0.8623 - accuracy: 0.9858 - val_loss: 0.8438 - val_accuracy: 0.9917\n",
      "Epoch 8/10\n",
      "121/121 [==============================] - 196s 2s/step - loss: 0.8285 - accuracy: 0.9930 - val_loss: 0.8145 - val_accuracy: 0.9928\n",
      "Epoch 9/10\n",
      "121/121 [==============================] - 198s 2s/step - loss: 0.7996 - accuracy: 0.9959 - val_loss: 0.7895 - val_accuracy: 0.9928\n",
      "Epoch 10/10\n",
      "121/121 [==============================] - 186s 2s/step - loss: 0.7739 - accuracy: 0.9972 - val_loss: 0.7668 - val_accuracy: 0.9938\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('modelATIS.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "train_history = model.fit(\n",
    "    train_data, y_train,\n",
    "    validation_split=0.20,\n",
    "    epochs = 10,\n",
    "    callbacks=[checkpoint],\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "accepted-restriction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "history_dict = train_history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, (len(history_dict['loss']) + 1))\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "standard-zealand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "acc_values = history_dict['accuracy']\n",
    "val_acc_values = history_dict['val_accuracy']\n",
    "epochs = range(1, (len(history_dict['accuracy']) + 1))\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-firmware",
   "metadata": {},
   "source": [
    "<p> The figure 1 gives the loss value. As the epochs are increased the loss values are decreased, this denotes that the model is working well with the intents and also it is able to understand the context better.</p>\n",
    "\n",
    "<p> The figure 2 graph also comes in support of the model. The accuracy is is increased which means the model can be able to detect some complex intents when tested. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "catholic-polish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(799, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawPreds = model.predict(test_data)\n",
    "rawPreds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "experienced-abraham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "799"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Preds = []\n",
    "\n",
    "for j in range(rawPreds.shape[0]):\n",
    "    pos = rawPreds[j].argmax()\n",
    "    Preds.append(y_test.columns[pos])\n",
    "    \n",
    "len(Preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "upper-feelings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "  atis_abbreviation       1.00      1.00      1.00        33\n",
      "      atis_aircraft       1.00      1.00      1.00         9\n",
      "       atis_airfare       1.00      1.00      1.00        48\n",
      "       atis_airline       1.00      1.00      1.00        38\n",
      "        atis_flight       0.99      1.00      1.00       627\n",
      "   atis_flight_time       1.00      1.00      1.00         1\n",
      "atis_ground_service       1.00      1.00      1.00        36\n",
      "      atis_quantity       1.00      0.43      0.60         7\n",
      "\n",
      "           accuracy                           0.99       799\n",
      "          macro avg       1.00      0.93      0.95       799\n",
      "       weighted avg       1.00      0.99      0.99       799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Preds, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-refund",
   "metadata": {},
   "source": [
    "<p> The classification report is the final draft which gives us the brief about the model. We can see that the model is giving us 99% accuracy on detecting the intent. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-grenada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "amateur-lighter",
   "metadata": {},
   "source": [
    "## Intent Classification using LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-rabbit",
   "metadata": {},
   "source": [
    "<p> This is the same dataset as previous one, in this experiment we are using LSTM. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "framed-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "laughing-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(r'D:\\Surrey\\Semester\\Semester 2\\NLP\\atis_intents_train.csv', names=['target', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "quality-powell",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv(r'D:\\Surrey\\Semester\\Semester 2\\NLP\\atis_intents_test.csv', names=['target', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "wanted-picture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>i want to fly from boston at 838 am and arriv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>what flights are available from pittsburgh to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atis_flight_time</td>\n",
       "      <td>what is the arrival time in san francisco for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atis_airfare</td>\n",
       "      <td>cheapest airfare from tacoma to orlando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>atis_airfare</td>\n",
       "      <td>round trip fares from pittsburgh to philadelp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4829</th>\n",
       "      <td>atis_airfare</td>\n",
       "      <td>what is the airfare for flights from denver t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4830</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>do you have any flights from denver to baltim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>atis_airline</td>\n",
       "      <td>which airlines fly into and out of denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4832</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>does continental fly from boston to san franc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4833</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>is there a delta flight from denver to san fr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4834 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                target                                               text\n",
       "0          atis_flight   i want to fly from boston at 838 am and arriv...\n",
       "1          atis_flight   what flights are available from pittsburgh to...\n",
       "2     atis_flight_time   what is the arrival time in san francisco for...\n",
       "3         atis_airfare            cheapest airfare from tacoma to orlando\n",
       "4         atis_airfare   round trip fares from pittsburgh to philadelp...\n",
       "...                ...                                                ...\n",
       "4829      atis_airfare   what is the airfare for flights from denver t...\n",
       "4830       atis_flight   do you have any flights from denver to baltim...\n",
       "4831      atis_airline          which airlines fly into and out of denver\n",
       "4832       atis_flight   does continental fly from boston to san franc...\n",
       "4833       atis_flight   is there a delta flight from denver to san fr...\n",
       "\n",
       "[4834 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "narrow-formula",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>atis_abbreviation</th>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atis_aircraft</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atis_airfare</th>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atis_airline</th>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atis_flight</th>\n",
       "      <td>3666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atis_flight_time</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atis_ground_service</th>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atis_quantity</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     text\n",
       "target                   \n",
       "atis_abbreviation     147\n",
       "atis_aircraft          81\n",
       "atis_airfare          423\n",
       "atis_airline          157\n",
       "atis_flight          3666\n",
       "atis_flight_time       54\n",
       "atis_ground_service   255\n",
       "atis_quantity          51"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby('target').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "unexpected-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data.append(train_data.loc[train_data.target.isin(['atis_flight_time', 'atis_quantity']), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "effective-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder as OHE\n",
    "y_encoder=OHE().fit(np.array(train_data.target).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "stable-japan",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytr_encoded=y_encoder.transform(np.array(train_data.target).reshape(-1,1)).toarray()\n",
    "yts_encoded=y_encoder.transform(np.array(test_data.target).reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "japanese-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "naughty-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['lower_text']=train_data.text.map(lambda x: x.lower())\n",
    "test_data['lower_text']= test_data.text.map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "through-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "train_data[\"tokenized\"]= train_data.lower_text.map(word_tokenize)\n",
    "test_data[\"tokenized\"]= test_data.lower_text.map(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bored-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "def remove_stop(strings, stop_list):\n",
    "    classed=[s for s in strings if s not in stop_list]\n",
    "    return classed\n",
    "\n",
    "stop=stopwords.words('english')\n",
    "stop_punc=list(set(punctuation)) + stop\n",
    "\n",
    "train_data['selected']= train_data.tokenized.map(lambda df: remove_stop(df, stop_punc))\n",
    "test_data['selected']= test_data.tokenized.map(lambda df: remove_stop(df, stop_punc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "difficult-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "def normalize(text):\n",
    "    return \" \".join(text)\n",
    "\n",
    "stemmer=PorterStemmer()\n",
    "\n",
    "train_data['stemmed']=train_data.selected.map(lambda xs: [stemmer.stem(x) for x in xs])\n",
    "train_data['normalized']=train_data.stemmed.apply(normalize)\n",
    "\n",
    "test_data['stemmed']=test_data.selected.map(lambda xs: [stemmer.stem(x)for x in xs])\n",
    "test_data['normalized']=test_data.stemmed.apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "every-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer=Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(train_data.normalized)\n",
    "\n",
    "tokenized_train=tokenizer.texts_to_sequences(train_data.normalized)\n",
    "tokenized_test=tokenizer.texts_to_sequences(test_data.normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "round-stereo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "654"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index.keys().__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "subject-resident",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "train_padded=pad_sequences(tokenized_train, maxlen=20, padding='pre')\n",
    "test_padded=pad_sequences(tokenized_test, maxlen=20, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "artistic-fossil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4939, 20)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "above-latest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_x(data, tokenizer):\n",
    "    output_shape=[data.shape[0],\n",
    "                 data.shape[1],\n",
    "                 tokenizer.word_index.keys().__len__()]\n",
    "    results= np.zeros(output_shape)\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        for ii in range(data.shape[1]):\n",
    "            results[i, ii, data[i, ii]-1]=1\n",
    "    return results\n",
    "\n",
    "xtr_transformed=transform_x(train_padded, tokenizer)\n",
    "xts_transformed=transform_x(test_padded, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "necessary-granny",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, LSTM, BatchNormalization, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy as CC\n",
    "from tensorflow.keras.activations import relu, softmax\n",
    "from tensorflow.keras.initializers import he_uniform, glorot_uniform\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "class LSTMModel(object):\n",
    "    \n",
    "    def build_model(self, input_dim, output_shape, steps, dropout_rate, kernel_regularizer, bias_regularizer):\n",
    "        input_layer= Input(shape= (steps, input_dim))\n",
    "        \n",
    "        #make lstm_layer\n",
    "        lstm= LSTM(units= steps)(input_layer)\n",
    "        dense_1= Dense(output_shape, kernel_initializer= he_uniform(),\n",
    "                       bias_initializer= \"zeros\", \n",
    "                       kernel_regularizer= l2(l= kernel_regularizer),\n",
    "                       bias_regularizer= l2(l= bias_regularizer))(lstm)\n",
    "        x= BatchNormalization()(dense_1)\n",
    "        x= relu(x)\n",
    "        x= Dropout(rate= dropout_rate)(x)\n",
    "        o= Dense(output_shape, kernel_initializer= glorot_uniform(),\n",
    "                 bias_initializer= \"zeros\", \n",
    "                 kernel_regularizer= l2(l= kernel_regularizer), \n",
    "                 bias_regularizer= l2(l= bias_regularizer))(dense_1)\n",
    "        o= BatchNormalization()(o)\n",
    "        output= softmax(o, axis= 1)\n",
    "        \n",
    "        loss= CC()\n",
    "        metrics= AUC()\n",
    "        optimizer= Adam()\n",
    "        self.model= Model(inputs= [input_layer], outputs= [output])\n",
    "        self.model.compile(optimizer= optimizer, loss= loss, metrics= [metrics])\n",
    "        \n",
    "        \n",
    "    def train(self, x, y, validation_split, epochs):\n",
    "        self.model.fit(x, y, validation_split= validation_split, epochs= epochs)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "spatial-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps=xtr_transformed.shape[1]\n",
    "dim=xtr_transformed.shape[2]\n",
    "output_shape=ytr_encoded.shape[1]\n",
    "\n",
    "model=LSTMModel()\n",
    "model.build_model(input_dim=dim,\n",
    "                 output_shape=output_shape,\n",
    "                 steps=steps,\n",
    "                 dropout_rate=0.5,\n",
    "                 bias_regularizer=0.3,\n",
    "                 kernel_regularizer=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "natural-resolution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "124/124 [==============================] - 5s 21ms/step - loss: 6.9890 - auc: 0.7541 - val_loss: 5.2727 - val_auc: 0.8697\n",
      "Epoch 2/60\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 3.9138 - auc: 0.9456 - val_loss: 3.2801 - val_auc: 0.9646\n",
      "Epoch 3/60\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 2.3535 - auc: 0.9762 - val_loss: 2.2473 - val_auc: 0.9512\n",
      "Epoch 4/60\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 1.5406 - auc: 0.9877 - val_loss: 2.0054 - val_auc: 0.8637\n",
      "Epoch 5/60\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 1.1348 - auc: 0.9905 - val_loss: 1.6535 - val_auc: 0.8905\n",
      "Epoch 6/60\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.9098 - auc: 0.9941 - val_loss: 0.9878 - val_auc: 0.9782\n",
      "Epoch 7/60\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.7803 - auc: 0.9951 - val_loss: 0.9267 - val_auc: 0.9777\n",
      "Epoch 8/60\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.6922 - auc: 0.9957 - val_loss: 0.7734 - val_auc: 0.9866\n",
      "Epoch 9/60\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.6229 - auc: 0.9973 - val_loss: 0.7804 - val_auc: 0.9864\n",
      "Epoch 10/60\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.5670 - auc: 0.9985 - val_loss: 0.7645 - val_auc: 0.9868\n",
      "Epoch 11/60\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.5054 - auc: 0.9985 - val_loss: 0.6055 - val_auc: 0.9908\n",
      "Epoch 12/60\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.4663 - auc: 0.9988 - val_loss: 0.6738 - val_auc: 0.9888\n",
      "Epoch 13/60\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.4369 - auc: 0.9988 - val_loss: 0.5595 - val_auc: 0.9915\n",
      "Epoch 14/60\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.4059 - auc: 0.9989 - val_loss: 0.5972 - val_auc: 0.9907\n",
      "Epoch 15/60\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.3760 - auc: 0.9990 - val_loss: 0.5297 - val_auc: 0.9917\n",
      "Epoch 16/60\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.3577 - auc: 0.9993 - val_loss: 0.5295 - val_auc: 0.9916\n",
      "Epoch 17/60\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.3374 - auc: 0.9994 - val_loss: 0.4395 - val_auc: 0.9935\n",
      "Epoch 18/60\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.3129 - auc: 0.9993 - val_loss: 0.4377 - val_auc: 0.9926\n",
      "Epoch 19/60\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2943 - auc: 0.9994 - val_loss: 0.4566 - val_auc: 0.9931\n",
      "Epoch 20/60\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.2869 - auc: 0.9996 - val_loss: 0.4159 - val_auc: 0.9935\n",
      "Epoch 21/60\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2775 - auc: 0.9994 - val_loss: 0.4507 - val_auc: 0.9930\n",
      "Epoch 22/60\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2630 - auc: 0.9996 - val_loss: 0.3984 - val_auc: 0.9939\n",
      "Epoch 23/60\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.2505 - auc: 0.9996 - val_loss: 0.3542 - val_auc: 0.9956\n",
      "Epoch 24/60\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2403 - auc: 0.9997 - val_loss: 0.3584 - val_auc: 0.9955\n",
      "Epoch 25/60\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 0.2276 - auc: 0.9998 - val_loss: 0.3255 - val_auc: 0.9957\n",
      "Epoch 26/60\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2221 - auc: 0.9997 - val_loss: 0.3321 - val_auc: 0.9960\n",
      "Epoch 27/60\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2143 - auc: 0.9996 - val_loss: 0.3215 - val_auc: 0.9962\n",
      "Epoch 28/60\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.2060 - auc: 0.9996 - val_loss: 0.3129 - val_auc: 0.9955\n",
      "Epoch 29/60\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.1958 - auc: 0.9998 - val_loss: 0.2804 - val_auc: 0.9967\n",
      "Epoch 30/60\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.1934 - auc: 0.9998 - val_loss: 0.3018 - val_auc: 0.9966\n",
      "Epoch 31/60\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.1858 - auc: 0.9998 - val_loss: 0.2747 - val_auc: 0.9964\n",
      "Epoch 32/60\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.1731 - auc: 0.9998 - val_loss: 0.2766 - val_auc: 0.9960\n",
      "Epoch 33/60\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 0.1707 - auc: 0.9999 - val_loss: 0.2584 - val_auc: 0.9968\n",
      "Epoch 34/60\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.1665 - auc: 0.9998 - val_loss: 0.2821 - val_auc: 0.9961\n",
      "Epoch 35/60\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.1661 - auc: 0.9999 - val_loss: 0.2456 - val_auc: 0.9971\n",
      "Epoch 36/60\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.1601 - auc: 0.9997 - val_loss: 0.2297 - val_auc: 0.9972\n",
      "Epoch 37/60\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.1506 - auc: 0.9999 - val_loss: 0.2281 - val_auc: 0.9970\n",
      "Epoch 38/60\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.1484 - auc: 0.9999 - val_loss: 0.2207 - val_auc: 0.9967\n",
      "Epoch 39/60\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.1439 - auc: 0.9999 - val_loss: 0.2252 - val_auc: 0.9974\n",
      "Epoch 40/60\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.1408 - auc: 0.9999 - val_loss: 0.2152 - val_auc: 0.9971\n",
      "Epoch 41/60\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.1363 - auc: 0.9999 - val_loss: 0.2267 - val_auc: 0.9966\n",
      "Epoch 42/60\n",
      "124/124 [==============================] - 1s 10ms/step - loss: 0.1339 - auc: 0.9999 - val_loss: 0.2173 - val_auc: 0.9969\n",
      "Epoch 43/60\n",
      "124/124 [==============================] - 1s 11ms/step - loss: 0.1293 - auc: 0.9999 - val_loss: 0.2101 - val_auc: 0.9966\n",
      "Epoch 44/60\n",
      "124/124 [==============================] - 1s 10ms/step - loss: 0.1279 - auc: 0.9998 - val_loss: 0.2118 - val_auc: 0.9968\n",
      "Epoch 45/60\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 0.1241 - auc: 0.9999 - val_loss: 0.1939 - val_auc: 0.9971\n",
      "Epoch 46/60\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.1204 - auc: 0.9999 - val_loss: 0.2020 - val_auc: 0.9965\n",
      "Epoch 47/60\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.1187 - auc: 1.0000 - val_loss: 0.2005 - val_auc: 0.9971\n",
      "Epoch 48/60\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.1170 - auc: 0.9999 - val_loss: 0.1922 - val_auc: 0.9972\n",
      "Epoch 49/60\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.1144 - auc: 1.0000 - val_loss: 0.2036 - val_auc: 0.9968\n",
      "Epoch 50/60\n",
      "124/124 [==============================] - 2s 16ms/step - loss: 0.1128 - auc: 1.0000 - val_loss: 0.1870 - val_auc: 0.9968\n",
      "Epoch 51/60\n",
      "124/124 [==============================] - 1s 12ms/step - loss: 0.1097 - auc: 1.0000 - val_loss: 0.1807 - val_auc: 0.9960\n",
      "Epoch 52/60\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.1061 - auc: 1.0000 - val_loss: 0.2123 - val_auc: 0.9945\n",
      "Epoch 53/60\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 0.1091 - auc: 0.9999 - val_loss: 0.1809 - val_auc: 0.9963\n",
      "Epoch 54/60\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.1023 - auc: 1.0000 - val_loss: 0.1824 - val_auc: 0.9967\n",
      "Epoch 55/60\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.0982 - auc: 1.0000 - val_loss: 0.1762 - val_auc: 0.9954\n",
      "Epoch 56/60\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.0968 - auc: 1.0000 - val_loss: 0.1694 - val_auc: 0.9966\n",
      "Epoch 57/60\n",
      "124/124 [==============================] - 2s 18ms/step - loss: 0.0939 - auc: 1.0000 - val_loss: 0.1773 - val_auc: 0.9959\n",
      "Epoch 58/60\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.0925 - auc: 1.0000 - val_loss: 0.1690 - val_auc: 0.9965\n",
      "Epoch 59/60\n",
      "124/124 [==============================] - 2s 17ms/step - loss: 0.0924 - auc: 0.9998 - val_loss: 0.1652 - val_auc: 0.9970\n",
      "Epoch 60/60\n",
      "124/124 [==============================] - 2s 14ms/step - loss: 0.0897 - auc: 1.0000 - val_loss: 0.1868 - val_auc: 0.9958\n"
     ]
    }
   ],
   "source": [
    "model.train(xtr_transformed, ytr_encoded, 0.2, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "annual-category",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "  atis_abbreviation       0.85      1.00      0.92       147\n",
      "      atis_aircraft       0.97      0.94      0.96        81\n",
      "       atis_airfare       1.00      0.99      0.99       423\n",
      "       atis_airline       0.99      0.87      0.93       157\n",
      "        atis_flight       1.00      1.00      1.00      3666\n",
      "   atis_flight_time       0.96      0.96      0.96       108\n",
      "atis_ground_service       0.97      1.00      0.99       255\n",
      "      atis_quantity       1.00      1.00      1.00       102\n",
      "\n",
      "           accuracy                           0.99      4939\n",
      "          macro avg       0.97      0.97      0.97      4939\n",
      "       weighted avg       0.99      0.99      0.99      4939\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "prediction=y_encoder.inverse_transform(model.predict(xtr_transformed))\n",
    "print(classification_report(train_data.target, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-austria",
   "metadata": {},
   "source": [
    "<p> By programming through LSTM algorithm we can see the training data accuracy is 98%. So the training is recognized well by the library. The next step is whether this can be same in test data or not. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "regular-dependence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "  atis_abbreviation       0.60      1.00      0.75        33\n",
      "      atis_aircraft       0.83      0.56      0.67         9\n",
      "       atis_airfare       1.00      0.92      0.96        48\n",
      "       atis_airline       1.00      0.42      0.59        38\n",
      "        atis_flight       0.99      0.99      0.99       632\n",
      "   atis_flight_time       1.00      1.00      1.00         1\n",
      "atis_ground_service       0.97      0.97      0.97        36\n",
      "      atis_quantity       0.38      1.00      0.55         3\n",
      "\n",
      "           accuracy                           0.95       800\n",
      "          macro avg       0.85      0.86      0.81       800\n",
      "       weighted avg       0.97      0.95      0.95       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "prediction_test= y_encoder.inverse_transform(model.predict(xts_transformed))\n",
    "print(classification_report(test_data.target, prediction_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-willow",
   "metadata": {},
   "source": [
    "<p> LSTM test data accuracy is same as train data, which is 98%. This means on an average this model will give 98% accurate data. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-advancement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "broke-poker",
   "metadata": {},
   "source": [
    "## Intent Classification using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "sharing-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import spacy\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-parts",
   "metadata": {},
   "source": [
    "<p> The library Spacy is also one of the most used library for intent classifiers. The following experiment is a failed experiment because I need, \"en_vectors_we_lg\" and this doesn't supports in the latest version of Spacy. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "pursuant-contemporary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[x] No compatible package found for 'en_vectors_web_lg' (spaCy v3.2.4)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 14:50:48.321987: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-28 14:50:48.322023: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] As of spaCy v3.0, model symlinks are not supported anymore. You can load\n",
      "trained pipeline packages using their full names or from a directory path.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 14:50:57.250268: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-28 14:50:57.250295: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "DeprecationWarning: The command link is deprecated.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_vectors_web_lg\n",
    "!python -m spacy link en_vectors_web_lg en_vectors_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "higher-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'D:\\Surrey\\Semester\\Semester 2\\NLP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "static-whale",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    with open(path, 'r') as csvfile:\n",
    "        readCSV=csv.reader(csvfile, delimiter=',')\n",
    "        labels=[]\n",
    "        sentences=[]\n",
    "        for row in readCSV:\n",
    "            label=row[0]\n",
    "            sentence=row[1]\n",
    "            labels.append(label)\n",
    "            sentences.append(sentence)\n",
    "    return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "close-injury",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' i would like to find a flight from charlotte to las vegas that makes a stop in st. louis', ' on april first i need a ticket from tacoma to san jose departing before 7 am', ' on april first i need a flight going from phoenix to san diego'] \n",
      "\n",
      "['atis_flight', 'atis_airfare', 'atis_flight']\n"
     ]
    }
   ],
   "source": [
    "sentences_test, labels_test=read_data(r'D:\\Surrey\\Semester\\Semester 2\\NLP\\atis_intents_test.csv')\n",
    "print(sentences_test[:3], '\\n')\n",
    "print(labels_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "wound-toddler",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, labels_train = read_data(r'D:\\Surrey\\Semester\\Semester 2\\NLP\\atis_intents_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "provincial-subcommittee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4833 rows & 2 columns\n"
     ]
    }
   ],
   "source": [
    "df1=pd.read_csv(r'D:\\Surrey\\Semester\\Semester 2\\NLP\\atis_intents_train.csv', delimiter=',')\n",
    "df1.dataframeName='atis_intents_train.csv'\n",
    "nRow, nCol,= df1.shape\n",
    "print(f'{nRow} rows & {nCol} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "freelance-talent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atis_flight</th>\n",
       "      <th>i want to fly from boston at 838 am and arrive in denver at 1110 in the morning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>flights from cleveland to kansas city on monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4022</th>\n",
       "      <td>atis_ground_service</td>\n",
       "      <td>what ground transportation is available at th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>atis_abbreviation</td>\n",
       "      <td>what is mco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2865</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>show me the flights from baltimore to oakland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>i need a flight this sunday from miami to las...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>show me the flights from baltimore to oakland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4826</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>please list all flights from san francisco to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3460</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>i want to go from boston to oakland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3333</th>\n",
       "      <td>atis_airfare</td>\n",
       "      <td>what's the lowest round trip fare from dallas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4054</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>show me the flights from atlanta to boston</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              atis_flight  \\\n",
       "795           atis_flight   \n",
       "4022  atis_ground_service   \n",
       "393     atis_abbreviation   \n",
       "2865          atis_flight   \n",
       "274           atis_flight   \n",
       "280           atis_flight   \n",
       "4826          atis_flight   \n",
       "3460          atis_flight   \n",
       "3333         atis_airfare   \n",
       "4054          atis_flight   \n",
       "\n",
       "      i want to fly from boston at 838 am and arrive in denver at 1110 in the morning  \n",
       "795     flights from cleveland to kansas city on monday                                \n",
       "4022   what ground transportation is available at th...                                \n",
       "393                                         what is mco                                \n",
       "2865      show me the flights from baltimore to oakland                                \n",
       "274    i need a flight this sunday from miami to las...                                \n",
       "280       show me the flights from baltimore to oakland                                \n",
       "4826   please list all flights from san francisco to...                                \n",
       "3460                i want to go from boston to oakland                                \n",
       "3333   what's the lowest round trip fare from dallas...                                \n",
       "4054         show me the flights from atlanta to boston                                "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "blind-whole",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atis_flight</th>\n",
       "      <th>i want to fly from boston at 838 am and arrive in denver at 1110 in the morning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4833</td>\n",
       "      <td>4833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>8</td>\n",
       "      <td>4498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>what is fare code h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3665</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        atis_flight  \\\n",
       "count          4833   \n",
       "unique            8   \n",
       "top     atis_flight   \n",
       "freq           3665   \n",
       "\n",
       "        i want to fly from boston at 838 am and arrive in denver at 1110 in the morning  \n",
       "count                                                4833                                \n",
       "unique                                               4498                                \n",
       "top                                   what is fare code h                                \n",
       "freq                                                    8                                "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "neither-acrobat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels :- 4834\n",
      "[4 4 5 2 2 4 1 4 4 6 4 4 4 4 2 6 4 4 4 4 4 4 1 2 4 3 4 6 4 2 4 4 4 4 2 3 4\n",
      " 4 4 4 3 3 4 3 6 0 4 4 5 4 4 4 0 4 4 4 4 4 3 4 6 3 4 4 4 4 0 4 4 4 4 1 2 4\n",
      " 4 4 4 4 4 4 3 4 4 4 4 4 4 4 2 4 6 7 4 4 4 4 4 4 4 4]\n",
      "Length of y :-  (4834,)\n",
      "Number of labels :- 800\n",
      "[4 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 6 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 2 3 5]\n",
      "Length of y :-  (800,)\n"
     ]
    }
   ],
   "source": [
    "def label_encoding(labels):\n",
    "    # Calculate the length of labels\n",
    "\n",
    "    n_labels = len(labels)\n",
    "    print('Number of labels :-',n_labels)\n",
    "    \n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    # instantiate labelencoder object\n",
    "    le = LabelEncoder()\n",
    "    y =le.fit_transform(labels)\n",
    "    print(y[:100])\n",
    "    print('Length of y :- ',y.shape)\n",
    "    return y\n",
    "\n",
    "train_y = label_encoding(labels_train)\n",
    "test_y = label_encoding(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "amazing-special",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.hist(train_y)\n",
    "plt.title('Intent Labels')\n",
    "plt.xlabel('Types')\n",
    "plt.ylabel('Frequency')\n",
    "#df1['atis_flight'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-provision",
   "metadata": {},
   "source": [
    "<p>The above visualisation shows the number of intent present in the dataset. As the program needs some specific library to go forward. This experiment is halted in between. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-template",
   "metadata": {},
   "source": [
    "## References\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-suite",
   "metadata": {},
   "source": [
    "<p> Links : -</p>\n",
    "   <p> 1. https://blog.vsoftconsulting.com/blog/intent-classification-and-its-significance-in-chatbot-develop </p>\n",
    "   <p> 2. https://paperswithcode.com/task/intent-classification </p>\n",
    "   <p>3. https://dasha.ai/en-us/blog/intent-classification </p>\n",
    "   <p> 4. https://www.helpshift.com/glossary/intent-classification/ </p>\n",
    "   <p> 5. https://monkeylearn.com/blog/intent-classification/#:~:text=Intent%20classification%20is%20the%20automated,%2C%20Unsubscribe%2C%20and%20Demo%20Request.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-alias",
   "metadata": {},
   "source": [
    "<p> This is first python file in which I have tried various experiments using Python NLTK libraries. The second Python file is demonstration of Intent based chatbot, the file will be executed through different inbuilt python file. The execution direction will be given at the start of the program. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-procedure",
   "metadata": {},
   "source": [
    "<p> The folder named as, 'Intent Chatbot' consists of 4 different python files which are related to each other. There is a separate 'ReadMe.txt' file on how to execute that folder.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
